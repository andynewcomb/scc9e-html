<chapter id="scc9e-ch04" number="4" title="Chapter 4: Sample Surveys in the Real World" start-numbering-at="4" numbered="true">
<section id="scc9e-ch04-sec-01" block_type="chapter" title="Sample Surveys in the Real World" numbered="false" level="1" print_page="63">
<p id="scc9e-ch04-p-01" block_type="CN">4</p>
<p id="scc9e-ch04-p-02" block_type="CT">Sample Surveys in the Real World</p>
<p id="scc9e_page_63" block_type="page_start" data-margin-content="right">63</p>
<figure id="scc9e-ch04-unfig-01" block_type="UN-FIGURE" numbered="false" mmtype="image" mmsrc="" attr="" data-filename="17MOORESCC-MSE_9e_CO04.html">
<layout align="right" width="medium" border="false"/>
<image asset-id="scc9e-ch04-img-01" alt="image" src="asset/ch4/17MOORESCC-MSE_9e_CO04.jpg"/>
<asset_source><phrase block_type="PH-CL">Tetra Images/SuperStock</phrase></asset_source>
</figure>
<box id="scc9e-ch04-box-01" numbered="false" block_type="BX4-H-ri">
<p id="scc9e-ch04-p-04" block_type="BX4-TXT-first"><phrase block_type="BX4-H-ri">CASE STUDY</phrase> An opinion poll talks to 1000 people chosen at random, announces its results, and announces a margin of error. Should we be happy? Perhaps not. Many polls don&#8217;t tell the whole truth about their samples. The Pew Research Center for the People and the Press did tell the whole truth about its sampling methods. Here it is.</p>
<p id="scc9e-ch04-p-05" block_type="BX4-TXT-I">Most polls are taken by telephone, dialing numbers at random to get a random sample of households. After eliminating fax and business numbers, Pew had to call 2879 residential numbers to get its sample of 1000 people. Here&#8217;s the breakdown:</p>
<table id="scc9e-ch04-untab-01" numbered="false" block_type="UN-TABLE" attr="65">
<tbody>
<tr>
<td align="center" block_type="BX4-TXT-I">Never answered phone</td>
<td align="center" block_type="BX4-TXT-I">938</td>
</tr>
<tr>
<td align="center" block_type="BX4-TXT-I">Answered but refused</td>
<td align="center" block_type="BX4-TXT-I">678</td>
</tr>
<tr>
<td align="center" block_type="BX4-TXT-I">Not eligible: no person aged 18 or older, or language barrier</td>
<td align="center" block_type="BX4-TXT-I">221</td>
</tr>
<tr>
<td align="center" block_type="BX4-TXT-I">Incomplete interview</td>
<td align="center" block_type="BX4-TXT-I">42</td>
</tr>
<tr>
<td align="center" block_type="BX4-TXT-I">Complete interview</td>
<td align="center" block_type="BX4-TXT-I">1000</td>
</tr>
<tr class="tborder">
<td align="center" block_type="BX4-TXT-I">Total called</td>
<td align="center" block_type="BX4-TXT-I">2879</td>
</tr>
</tbody>
</table>
<p id="scc9e-ch04-p-06" block_type="BX4-TXT-I">Out of 2879 working residential phone numbers, 33&#37; never answered. Of those who answered, 24&#37; refused to talk. The overall rate of nonresponse (people who never answered, refused, or would not complete the interview) was 1658 out of 2879, or 58&#37;. Pew called every number five times over a five-day period, at different times of day and on different days of the week. Many polls call only once, and it is usual to find that more than half of those who answer refuse to talk. Although Pew did obtain the desired sample of 1000 people, can we trust the results of this poll to make conclusions about people with residential phones? Can the results of the poll be extended to people who only have cell phones? By the end of this chapter, you will learn how to answer this question.</p>
</box>
</section>
<section id="scc9e-ch04-sec-02" block_type="h1" chapter="ch4" numbered="false" level="1" print_page="64">
<section-metadata><section-title>How sample surveys go wrong</section-title></section-metadata>
<p id="scc9e_page_64" block_type="page_start" data-margin-content="left">64</p>
<p id="scc9e-ch04-p-08" block_type="TXT-ni">Random sampling eliminates bias in choosing a sample and allows control of variability. So once we see the magic words &#8220;randomly selected&#8221; and &#8220;margin of error,&#8221; do we know we have trustworthy information before us? It certainly beats voluntary response, but not always by as much as we might hope. Sampling in the real world is more complex and less reliable than choosing an SRS from a list of names in a textbook exercise. Confidence statements do not reflect all the sources of error that are present in practical sampling.</p>
<box id="scc9e-ch04-box-02" numbered="false" block_type="BX1">
<p id="scc9e-ch04-p-09" block_type="BX1-T">Errors in sampling</p>
<p id="scc9e-ch04-p-10" block_type="BX1-TXT-ni"><strong>Sampling errors</strong> are errors caused by the act of taking a sample. They cause sample results to be different from the results of a census.</p>
<p id="scc9e-ch04-p-11" block_type="BX1-TXT-i"><strong>Random sampling error</strong> is the deviation between the sample statistic and the population parameter caused by chance in selecting a random sample. The margin of error in a confidence statement includes <em>only</em> random sampling error.</p>
<p id="scc9e-ch04-p-12" block_type="BX1-TXT-i"><strong>Nonsampling errors</strong> are errors not related to the act of selecting a sample from the population. They can be present even in a census.</p>
</box>
<p id="scc9e-ch04-p-13" block_type="TXT-ni">Most sample surveys are afflicted by errors other than random sampling errors. These errors can introduce bias that makes a confidence statement meaningless. Good sampling technique includes the art of reducing all sources of error. Part of this art is the science of statistics, with its random samples and confidence statements. In practice, however, good statistics isn&#8217;t all there is to good sampling. Let&#8217;s look at sources of errors in sample surveys and at how samplers combat them.</p>
</section>
<section id="scc9e-ch04-sec-03" block_type="h1" chapter="ch4" numbered="false" level="1" print_page="64">
<section-metadata><section-title>Sampling errors</section-title></section-metadata>
<p id="scc9e-ch04-p-14" block_type="TXT-ni"><em>Random sampling error</em> is one kind of sampling error. The margin of error tells us how serious random sampling error is, and we can control it by choosing the size of our random sample. Another source of sampling error is the use of <em>bad sampling methods</em>, such as voluntary response. We can avoid bad methods. Other sampling errors are not so easy to handle. Sampling begins with a list of individuals from which we will draw our sample. This list is called the <strong>sampling frame</strong>. Ideally, the sampling frame should list every individual in the population. Because a list of the entire population is rarely available, most samples suffer from some degree of <em>undercoverage</em>.</p>
<p id="scc9e_page_65" block_type="page_start" data-margin-content="right">65</p>
<box id="scc9e-ch04-box-03" numbered="false" block_type="BX1">
<p id="scc9e-ch04-p-16" block_type="BX1-T">Undercoverage</p>
<p id="scc9e-ch04-p-17" block_type="BX1-TXT-ni"><strong>Undercoverage</strong> occurs when some groups in the population are left out of the process of choosing the sample.</p>
</box>
<figure id="scc9e-ch04-unfig-02" block_type="UN-FIGURE" numbered="false" mmtype="image" mmsrc="" attr="" data-filename="4_17MOORESCC-MSE_9e_Car_04_01.html">
<layout align="right" width="medium" border="false"/>
<image asset-id="scc9e-ch04-img-02" alt="image" src="asset/ch4/17MOORESCC-MSE_9e_Car_04_01.jpg"/>
</figure>
<p id="scc9e-ch04-p-18" block_type="TXT">If the sampling frame leaves out certain classes of people, even random samples from that frame will be biased. Using telephone directories as the frame for a telephone survey, for example, would miss everyone with an unlisted residential telephone number, everyone who cannot afford a residential phone, and everyone who has only a cell phone. Even if we consider only those with residential telephones, more than half the households in many large cities have unlisted numbers, so massive undercoverage and bias against urban areas would result. In fact, telephone surveys use random digit dialing equipment, which dials telephone numbers in selected regions at random. In effect, the sampling frame contains all residential telephone numbers.</p>
<box id="scc9e-ch04-box-04" numbered="false" block_type="EXP" data-filename="example_4_1.html">
<p id="scc9e-ch04-p-19" block_type="EXP-T"><phrase block_type="EXP-N-ri">EXAMPLE 1</phrase> Did we miss anyone?</p>
<p id="scc9e-ch04-p-20" block_type="EXP-first">Most opinion polls can&#8217;t afford even to attempt full coverage of the population of all adult residents of the United States. The interviews are done by telephone, thus missing the 2&#37; of households without phones. Only <em>households</em> are contacted, so students in dormitories, prison inmates, and most members of the armed forces are left out. So are the homeless and people staying in shelters. Many polls interview only in English, which leaves some immigrant households out of their samples.</p>
</box>
<p id="scc9e-ch04-p-21" block_type="TXT">The kinds of undercoverage found in most sample surveys are most likely to leave out people who are young or poor or who move often. Nonetheless, random digit dialing comes close to producing a random sample of households with phones. Sampling errors in careful sample surveys are usually quite small. The real problems start when someone picks up (or doesn&#8217;t pick up) the phone. Now nonsampling errors take over.</p>
</section>
<section id="scc9e-ch04-sec-04" block_type="h1" chapter="ch4" numbered="false" level="1" print_page="66">
<section-metadata><section-title>Nonsampling errors</section-title></section-metadata>
<p id="scc9e_page_66" block_type="page_start" data-margin-content="left">66</p>
<p id="scc9e-ch04-p-23" block_type="TXT-ni">Nonsampling errors are those that can plague even a census. They include <strong>processing errors</strong>&#8212;mistakes in mechanical tasks such as doing arithmetic or entering responses into a computer. Fortunately, the wide availability and adoption of computers has made processing errors less common than in the past.</p>
<box id="scc9e-ch04-box-05" numbered="false" block_type="EXP" data-filename="example_4_2.html">
<p id="scc9e-ch04-p-24" block_type="EXP-T"><phrase block_type="EXP-N-ri">EXAMPLE 2</phrase> Computer-assisted interviewing</p>
<p id="scc9e-ch04-p-25" block_type="EXP-first">The days of the interviewer with a clipboard are past. Contemporary interviewers carry a laptop computer for face-to-face interviews or watch a computer screen as they carry out a telephone interview. Computer software manages the interview. The interviewer reads questions from the computer screen and uses the keyboard to enter the responses. The computer skips irrelevant items&#8212;once a respondent says that she has no children, further questions about her children never appear. The computer can check that answers to related questions are consistent with each other. It can even present questions in random order to avoid any bias due to always asking questions in the same order.</p>
<p id="scc9e-ch04-p-26" block_type="EXP-mid">Computer software also manages the record keeping. It keeps records of who has responded and prepares a file of data from the responses. The tedious process of transferring responses from paper to computer, once a source of processing errors, has disappeared. The computer even schedules the calls in telephone surveys, taking account of the respondent&#8217;s time zone and honoring appointments made by people who were willing to respond but did not have time when first called.</p>
</box>
<p id="scc9e-ch04-p-27" block_type="TXT">Another type of nonsampling error is <strong>response error</strong>, which occurs when a subject gives an incorrect response. A subject may lie about her age or income or about whether she has used illegal drugs. She may remember incorrectly when asked how many packs of cigarettes she smoked last week. A subject who does not understand a question may guess at an answer rather than appear ignorant. Questions that ask subjects about their behavior during a fixed time period are notoriously prone to response errors due to faulty memory. For example, the National Health Survey asks people how many times they have visited a doctor in the past year. Checking their responses against health records found that they failed to remember 60&#37; of their visits to a doctor. A survey that asks about sensitive issues can also expect response errors, as the next example illustrates.</p>
<p id="scc9e_page_67" block_type="page_start" data-margin-content="right">67</p>
<box id="scc9e-ch04-box-06" numbered="false" block_type="EXP" data-filename="example_4_3.html">
<p id="scc9e-ch04-p-29" block_type="EXP-T"><phrase block_type="EXP-N-ri">EXAMPLE 3</phrase> The effect of race</p>
<p id="scc9e-ch04-p-30" block_type="EXP-first">In 1989, New York City elected its first black mayor and the state of Virginia elected its first black governor. In both cases, samples of voters interviewed as they left their polling places predicted larger margins of victory than the official vote counts. The polling organizations were certain that some voters lied when interviewed because they felt uncomfortable admitting that they had voted against the black candidate. This phenomenon is known as &#8220;social desirability bias&#8221; and &#8220;the Bradley effect,&#8221; after Tom Bradley, the former black mayor of Los Angeles who lost the 1982 California gubernatorial election despite leading in final-day preelection polls.</p>
<p id="scc9e-ch04-p-31" block_type="EXP-mid">This effect attracted media attention during the 2008 presidential election. A few weeks before the election, polls predicted a victory, possibly a big one, for Barack Obama. Even so, Democrats worried that these polls might be overly optimistic because of the Bradley effect. In this case their fears were unfounded, but some political scientists claimed to detect the Bradley effect in polls predicting outcomes in primary races between Barack Obama and Hilary Clinton (for example, in the New Hampshire primary, polls predicted an 8 percentage point Obama victory, but Clinton won by 3 percentage points).</p>
</box>
<p id="scc9e-ch04-p-32" block_type="TXT-ni">Technology and attention to detail can minimize processing errors. Skilled interviewers greatly reduce response errors, especially in face-to-face interviews. There is no simple cure, however, for the most serious kind of nonsampling error, <em>nonresponse</em>.</p>
<figure id="scc9e-ch04-unfig-03" block_type="UN-FIGURE" numbered="false" mmtype="image" mmsrc="" attr="" data-filename="4_17MOORESCC-MSE_9e_Car_04_02.html">
<layout align="right" width="medium" border="false"/>
<image asset-id="scc9e-ch04-img-03" alt="image" src="asset/ch4/17MOORESCC-MSE_9e_Car_04_02.jpg"/>
</figure>
<box id="scc9e-ch04-box-07" numbered="false" block_type="BX1">
<p id="scc9e-ch04-p-33" block_type="BX1-T">Nonresponse</p>
<p id="scc9e-ch04-p-34" block_type="BX1-TXT-ni"><strong>Nonresponse</strong> is the failure to obtain data from an individual selected for a sample. Most nonresponse happens because some subjects can&#8217;t be contacted or because some subjects who are contacted refuse to cooperate.</p>
</box>
<p id="scc9e-ch04-p-35" block_type="TXT-ni">Nonresponse is the most serious problem facing sample surveys. People are increasingly reluctant to answer questions, particularly over the phone. The rise of telemarketing, voicemail, and caller ID drives down response to telephone surveys. Gated communities and buildings guarded by doormen prevent face-to-face interviews. Nonresponse can bias sample survey results because different groups have different rates of nonresponse. Refusals are higher in large cities and among the elderly, for example. Bias due to nonresponse can easily overwhelm the random sampling error described by a survey&#8217;s margin of error.</p>
<p id="scc9e_page_68" block_type="page_start" data-margin-content="left">68</p>
<box id="scc9e-ch04-box-08" numbered="false" block_type="EXP" data-filename="example_4_4.html">
<p id="scc9e-ch04-p-37" block_type="EXP-T"><phrase block_type="EXP-N-ri">EXAMPLE 4</phrase> How bad is nonresponse?</p>
<p id="scc9e-ch04-p-38" block_type="EXP-first">The U.S. Census Bureau&#8217;s American Community Survey (ACS) is a monthly survey of almost 300,000 housing units and replaced the U.S. Census Bureau&#8217;s &#8220;long form&#8221; that, in the past, was sent to some households in the every-10-years national census. Participation in the ACS is mandatory, and the U.S. Census Bureau follows up by telephone and then in person if a household fails to return the mail questionnaire.</p>
<p id="scc9e-ch04-p-39" block_type="EXP-mid">The ACS has the lowest nonresponse rate of any poll we know: in 2013, only about 1.3&#37; of the households in the sample refused to respond; the overall nonresponse rate, including &#8220;never at home&#8221; and other causes, was 10.1&#37;. This is a stark contrast in nonresponse from previous years&#8212;in 2012, the total nonresponse rate was only 2.7&#37;. In October 2013, there was a government shutdown. During that time, &#8220;the ACS did not have a second mailing, a telephone followup, or a person followup operation for the October 2013 housing unit panel. . . . This caused a drop in the annual housing unit response rate of about 7 percentage points.&#8221; If October 2013 is excluded from the ACS when considering nonresponse, the total nonresponse rate for 2013 was only 2.9&#37;, similar to previous years.</p>
<p id="scc9e-ch04-p-40" block_type="EXP-mid">Another survey that has a remarkable response rate is the University of Chicago&#8217;s General Social Survey (GSS), the nation&#8217;s most important social survey. The GSS (<link href="example_1_7.html">Example 7</link> in <link href="scc9e-ch01.xml">Chapter 1</link>) contacts its sample in person, and it is run by a university. Despite these advantages, its recent surveys have a 30&#37; rate of nonresponse.</p>
<p id="scc9e-ch04-p-41" block_type="EXP-mid">What about polls done by the media and by market research and opinion-polling firms? We often don&#8217;t know their rates of nonresponse because they won&#8217;t say. That itself is a bad sign. The Pew poll we looked at in the Case Study suggests how bad things are. Pew got 1221 responses (of whom 1000 were in the population they targeted) and 1658 who were never at home, refused, or would not finish the interview. That&#8217;s a nonresponse rate of 1658 out of 2879, or 58&#37;. The Pew researchers were more thorough than many pollsters. Insiders say that nonresponse often reaches 75&#37; or 80&#37; of an opinion poll&#8217;s original sample.</p>
<p id="scc9e-ch04-p-42" block_type="EXP-mid">The situation investigated in the Case Study was more promising than a recent Pew survey. In a December 2013 survey on social media use, the Pew Research Center provided a full disposition of the sampled phone numbers. Here are the details. Initially, 40,985 landline and 27,000 cell phones were dialed, with 11,260 of the landlines and 15,758 of the cell numbers being working numbers. Of these 27,018 working numbers, they were able to contact 17,335, or about 64&#37;, as a large portion of the calls went to voicemail. Among those contacted, about 15&#37; cooperated. Of those cooperating, some numbers were ineligible due to language barriers or contacting a child&#8217;s cell phone, and some calls were eventually broken off without being completed. To sum it up, the 27,018 working numbers dialed resulted in a final sample of 1801, giving a response rate of about 7&#37;, an estimate of the fraction of all <em>eligible</em> respondents in the sample who were ultimately interviewed.</p>
</box>
<p id="scc9e_page_69" block_type="page_start" data-margin-content="right">69</p>
<p id="scc9e-ch04-p-44" block_type="TXT">Sample surveyors know some tricks to reduce nonresponse. Carefully trained interviewers can keep people on the line if they answer at all. Calling back over longer time periods helps. So do letters sent in advance. Letters and many callbacks slow down the survey, so opinion polls that want fast answers to satisfy the media don&#8217;t use them. Even the most careful surveys find that nonresponse is a problem that no amount of expertise can fully overcome. That makes this reminder even more important:</p>
<box id="scc9e-ch04-box-09" numbered="false" block_type="BX1">
<p id="scc9e-ch04-p-45" block_type="BX1-T">What the margin of error doesn&#8217;t say</p>
<p id="scc9e-ch04-p-46" block_type="BX1-TXT-ni">The announced margin of error for a sample survey covers only random sampling error. Undercoverage, nonresponse, and other practical difficulties can cause large bias that is not covered by the margin of error.</p>
</box>
<p id="scc9e-ch04-p-47" block_type="TXT">Careful sample surveys warn us about the other kinds of error. The Pew Research Center, for example, says, &#8220;In addition to sampling error, one should bear in mind that question wording and practical difficulties in conducting surveys can introduce error or bias into the findings of opinion polls.&#8221; How true it is.</p>
<box id="scc9e-ch04-box-10" numbered="false" block_type="margin-statistics">
<p id="scc9e-ch04-p-49" block_type="MN-TXT"><image asset-id="scc9e-ch04-img-04" alt="image" src="asset/global_images/statistics_icon.jpg"/><phrase block_type="MN-T-ri">He started it!</phrase> A study of deaths in bar fights showed that in 90&#37; of the cases, the person who died started the fight. You shouldn&#8217;t believe this. If you killed someone in a fight, what would you say when the police ask you who started the fight? After all, dead men tell no tales. Now that&#8217;s nonresponse.</p>
</box>
<p id="scc9e-ch04-p-48" block_type="TXT">Does nonresponse make many sample surveys useless? Maybe not. We began this chapter with an account of a &#8220;standard&#8221; telephone survey done by the Pew Research Center. The Pew researchers also carried out a &#8220;rigorous&#8221; survey, with letters sent in advance, unlimited calls over eight weeks, letters by priority mail to people who refused, and so on. All this drove the rate of nonresponse down to 30&#37;, compared with 58&#37; for the standard survey. Pew then compared the answers to the same questions from the two surveys. The two samples were quite similar in age, sex, and race, though the rigorous sample was a bit more prosperous. The two samples also held similar opinions on all issues except one: race. People who at first refused to respond were less sympathetic toward the plights of blacks and other minorities than those who were willing to respond when contacted the first time. Overall, it appears that standard polls give reasonably accurate results. But, as in <link href="example_4_3.html">Example 3</link>, race is again an exception.</p>
</section>
<section id="scc9e-ch04-sec-05" block_type="h1" chapter="ch4" numbered="false" level="1" print_page="70">
<section-metadata><section-title>Wording questions</section-title></section-metadata>
<p id="scc9e_page_70" block_type="page_start" data-margin-content="left">70</p>
<p id="scc9e-ch04-p-51" block_type="TXT-ni">A final influence on the results of a sample survey is the exact wording of questions. It is surprisingly difficult to word questions so that they are completely clear. A survey that asks &#8220;Do you enjoy watching football?&#8221; will generate different answers based on the respondent&#8217;s understanding of &#8220;football&#8221; (American football or soccer).</p>
<box id="scc9e-ch04-box-11" numbered="false" block_type="EXP" data-filename="example_4_5.html">
<p id="scc9e-ch04-p-52" block_type="EXP-T"><phrase block_type="EXP-N-ri">EXAMPLE 5</phrase> Words make a big difference</p>
<p id="scc9e-ch04-p-53" block_type="EXP-first">In May 2013, the Pew Research Center and the <em>Washington Post</em>/ABC News conducted polls asking whether people felt the U.S. Department of Justice had the right to subpoena Associated Press reporters&#8217; phone records. Each survey phrased the question differently, and each survey found different results.</p>
<p id="scc9e-ch04-p-54" block_type="EXP-mid">When the Pew Research Center asked, &#8220;Do you approve or disapprove of the Justice Department&#8217;s decision to subpoena the phone records of AP journalists as part of an investigation into the disclosure of classified information?&#8221; 36&#37; of respondents approved. The <em>Washington Post</em>/ABC News survey said, &#8220;The AP reported classified information about U.S. anti-terrorism efforts and prosecutors have obtained AP&#8217;s phone records through a court order. Do you think this action by federal prosecutors is or is not justified?&#8221; Fifty-two (52&#37;) of respondents to this survey said that the action of federal prosecutors was justified.</p>
<p id="scc9e-ch04-p-55" block_type="EXP-mid">Before asking about approval or disapproval of the Justice Department&#8217;s actions, Pew asked how closely respondents had followed the issues that led up to the subpoena, and 64&#37; reported not following the news story too closely. Additionally, the difference in wording&#8212;&#8220;decision to subpoena&#8221; in the Pew Research survey versus &#8220;obtained . . . through a court order&#8221; used by the <em>Washington Post</em>/ABC News survey&#8212;could have led to legitimizing the actions of the Department of Justice and thus a higher &#8220;approval&#8221; for the Justice Department&#8217;s actions. Or, was the higher justification based on the inclusion of the mention of U.S. antiterrorism efforts? Or, perhaps the difference is due to Pew using &#8220;the Justice Department&#8221; and the <em>Washington Post</em>/ABC News using &#8220;federal prosecutors.&#8221; We cannot begin to determine which part of the wording affected the responses. As the Pew Research Center said in its article comparing the results of these two surveys, &#8220;each polling organization made good-faith efforts to describe the facts of the situation as accurately as possible, but the word choices and context make it impossible to identify one particular phrase or concept that tipped the public?s thinking.&#8221;</p>
</box>
<p id="scc9e_page_71" block_type="page_start" data-margin-content="right">71</p>
<figure id="scc9e-ch04-unfig-04" block_type="UN-FIGURE" numbered="false" mmtype="image" mmsrc="" attr="" data-filename="4_17MOORESCC-MSE_9e_Car_04_03.html">
<layout align="center" width="xlarge" border="false"/>
<image asset-id="scc9e-ch04-img-05" alt="image" src="asset/ch4/17MOORESCC-MSE_9e_Car_04_03.jpg"/>
<asset_source><phrase block_type="PH-CL">DOONESBURY &#169; 1989 G. B. Trudeau. Reprinted with permission of UNIVERSAL UCLICK. All rights reserved.</phrase></asset_source>
</figure>
<p id="scc9e-ch04-p-57" block_type="TXT">The wording of questions always influences the answers. If the questions are slanted to favor one response over others, we have another source of nonsampling error. A favorite trick is to ask if the subject favors some policy as a means to a desirable end: &#8220;Do you favor banning private ownership of handguns in order to reduce the rate of violent crime?&#8221; and &#8220;Do you favor imposing the death penalty in order to reduce the rate of violent crime?&#8221; are loaded questions that draw positive responses from people who are worried about crime. Here is another example of the influence of question wording.</p>
<box id="scc9e-ch04-box-12" numbered="false" block_type="EXP" data-filename="example_4_6.html">
<p id="scc9e-ch04-p-58" block_type="EXP-T"><phrase block_type="EXP-N-ri">EXAMPLE 6</phrase> Paying taxes</p>
<p id="scc9e-ch04-p-59" block_type="EXP-ni">In April 2015, a Gallup Poll asked two questions about the amount one pays in federal income taxes. Here are the two questions:</p>
<p id="scc9e-ch04-p-60" block_type="EXP-TXT-1"><em>Do you consider the amount of federal income tax you have to pay as too high, about right, or too low?</em></p>
<p id="scc9e-ch04-p-61" block_type="EXP-TXT-1"><em>Do you regard the income tax which you will have to pay this year as fair?</em></p>
<p id="scc9e-ch04-p-62" block_type="EXP-ni">The first question had 42&#37; of respondents say &#8220;about right&#8221; (51&#37; said &#8220;too high&#8221;), while the second question resulted in 56&#37; of respondents saying that the taxes they paid were &#8220;fair.&#8221; There appears to be a definite difference in opinions about taxes when people are asked about the amount they have to pay or whether it is fair.</p>
</box>
<p id="scc9e_page_72" block_type="page_start" data-margin-content="left">72</p>
<box id="scc9e-ch04-box-13" numbered="false" block_type="BX2">
<p id="scc9e-ch04-p-64" block_type="BX2-H">NOW IT&#8217;S YOUR TURN</p>
<question id="scc9e-ch04-ques-01" block_type="exercise_4_1.html">
<p id="scc9e-ch04-p-65" block_type="BX2-QUE"><phrase block_type="BX2-QUE-N-ri">4.1 Should we recycle?</phrase> Is the following question slanted toward a desired response? If so, how?</p>
<p id="scc9e-ch04-p-66" block_type="BX2-QUE"><em>In view of escalating environmental degradation and incipient resource depletion, would you favor economic incentives for recycling of resourceintensive consumer goods</em>?</p>
</question>
</box>
</section>
<section id="scc9e-ch04-sec-06" block_type="h1" chapter="ch4" numbered="false" level="1" print_page="72">
<section-metadata><section-title>How to live with nonsampling errors</section-title></section-metadata>
<p id="scc9e-ch04-p-67" block_type="TXT-ni">Nonsampling errors, especially nonresponse, are always with us. What should a careful sample survey do about this? First, <strong>substitute other households</strong> for the nonresponders. Because nonresponse is higher in cities, replacing nonresponders with other households in the same neighborhood may reduce bias. Once the data are in, all professional surveys use statistical methods to <strong>weight the responses</strong> in an attempt to correct sources of bias. If many urban households did not respond, the survey gives more weight to those that did respond. If too many women are in the sample, the survey gives more weight to the men. Here, for example, is part of a statement in the <em>New York Times</em> describing one of its sample surveys:</p>
<p id="scc9e-ch04-p-68" block_type="EXT-TXT"><em>The results have been weighted to take account of household size and number of telephone lines into the residence and to adjust for variations in the sample relating to geographic region, sex, race, age and education.</em></p>
<p id="scc9e-ch04-p-69" block_type="TXT-ni">The goal is to get results &#8220;as if&#8221; the sample matched the population in age, gender, place of residence, and other variables.</p>
<p id="scc9e-ch04-p-70" block_type="TXT">The practice of weighting creates job opportunities for statisticians. It also means that the results announced by a sample survey are rarely as simple as they seem to be. Gallup announces that it interviewed 1523 adults and found that 57&#37; of them bought a lottery ticket in the last 12 months. It would seem that because 57&#37; of 1523 is 868, Gallup found that 868 people in its sample had played the lottery. Not so. Gallup no doubt used some quite fancy statistics to weight the actual responses: 57&#37; is Gallup&#8217;s best estimate of what it would have found in the absence of nonresponse. Weighting does help correct bias. It usually also increases variability. The announced margin of error must take this into account, creating more work for statisticians.</p>
</section>
<section id="scc9e-ch04-sec-07" block_type="h1" chapter="ch4" numbered="false" level="1" print_page="72">
<section-metadata><section-title>Sample design in the real world</section-title></section-metadata>
<p id="scc9e-ch04-p-71" block_type="TXT-ni">The basic idea of sampling is straightforward: take an SRS from the population and use a statistic from your sample to estimate a parameter of the population. We now know that the sample statistic is altered behind the scenes to partly correct for nonresponse. The statisticians also have their hands on our beloved SRS. In the real world, most sample surveys use more complex designs.</p>
<p id="scc9e_page_73" block_type="page_start" data-margin-content="right">73</p>
<box id="scc9e-ch04-box-14" numbered="false" block_type="EXP" data-filename="example_4_7.html">
<p id="scc9e-ch04-p-73" block_type="EXP-T"><phrase block_type="EXP-N-ri">EXAMPLE 7</phrase> The Current Population Survey</p>
<p id="scc9e-ch04-p-74" block_type="EXP-first">The population that the Current Population Survey (CPS) is interested in consists of all households in the United States (including Alaska and Hawaii). The sample is <strong>chosen in stages</strong>. The Census Bureau divides the nation into 2007 geographic areas called primary sampling units (PSUs). These are generally groups of neighboring counties. At the first stage, 754 PSUs are chosen. This isn&#8217;t an SRS. If all PSUs had the same chance to be chosen, the sample might miss Chicago and Los Angeles. So 428 highly populated PSUs are automatically in the sample. The other 1579 are divided into 326 groups, called <strong>strata</strong>, by combining PSUs that are similar in various ways. One PSU is chosen at random to represent each stratum.</p>
<p id="scc9e-ch04-p-75" block_type="EXP-mid">Each of the 754 PSUs in the first-stage sample is divided into census blocks (smaller geographic areas). The blocks are also grouped into strata, based on such things as housing types and minority population. The households in each block are arranged in order of their location and divided into groups, called <strong>clusters</strong>, of about four households each. The final sample consists of samples of clusters (not of individual households) from each stratum of blocks. Interviewers go to all households in the chosen clusters. The samples of clusters within each stratum of blocks are also not SRSs. To be sure that the clusters spread out geographically, the sample starts at a random cluster and then takes, for example, every 10th cluster in the list.</p>
</box>
<p id="scc9e-ch04-p-76" block_type="TXT">The design of the CPS illustrates several ideas that are common in real-world samples that use face-to-face interviews. Taking the sample <em>in several stages</em> with <em>clusters</em> at the final stage saves travel time for interviewers by grouping the sample households first in PSUs and then in clusters. Note that clustering is not an aspect of all sampling strategies, but it can be quite helpful in situations like the CPS.</p>
<p id="scc9e-ch04-p-77" block_type="TXT">The most important refinement mentioned in <link href="example_4_7.html">Example 7</link> is <em>stratified sampling</em>.</p>
<box id="scc9e-ch04-box-15" numbered="false" block_type="BX1">
<p id="scc9e-ch04-p-78" block_type="BX1-T">Stratified sample</p>
<p id="scc9e-ch04-p-79" block_type="BX1-TXT-ni">To choose a <strong>stratified random sample</strong>:</p>
<p id="scc9e-ch04-p-80" block_type="BX1-NL-first"><strong>Step 1.</strong> Divide the sampling frame into distinct groups of individuals, called <strong>strata</strong>. Choose the strata according to any special interest you have in certain groups within the population or because the individuals in each stratum resemble each other.</p>
<p id="scc9e-ch04-p-81" block_type="BX1-NL-last"><strong>Step 2.</strong> Take a separate SRS in each stratum and combine these to make up the complete sample.</p>
</box>
<p id="scc9e_page_74" block_type="page_start" data-margin-content="left">74</p>
<p id="scc9e-ch04-p-83" block_type="TXT">We must, of course, choose the strata using facts about the population that are known before we take the sample. You might group a university&#8217;s students into undergraduate and graduate students or into those who live on campus and those who commute. Stratified samples have some advantages over an SRS. First, by taking a separate SRS in each stratum, we can set sample sizes to allow separate conclusions about each stratum. Second, a stratified sample usually has a smaller margin of error than an SRS of the same size. The reason is that the individuals in each stratum are more alike than the population as a whole, so working stratum by stratum eliminates some variability in the sample.</p>
<p id="scc9e-ch04-p-84" block_type="TXT">It may surprise you that stratified samples can violate one of the most appealing properties of the SRS&#8212;stratified samples need not give all individuals in the population the same chance to be chosen. Some strata may be deliberately overrepresented in the sample.</p>
<box id="scc9e-ch04-box-16" numbered="false" block_type="EXP" data-filename="example_4_8.html">
<p id="scc9e-ch04-p-85" block_type="EXP-T"><phrase block_type="EXP-N-ri">EXAMPLE 8</phrase> Stratifying a sample of students</p>
<p id="scc9e-ch04-p-86" block_type="EXP-first">A large university has 30,000 students, of whom 3000 are graduate students. An SRS of 500 students gives every student the same chance to be in the sample. That chance is</p>
<p id="scc9e-ch04-p-87" block_type="EXP-EQ"><phrase data-math="math_1"></phrase></p>
<p id="scc9e-ch04-p-88" block_type="EXP-mid">We expect an SRS of 500 to contain only about 50 grad students&#8212; because grad students make up 10&#37; of the population, we expect them to make up about 10&#37; of an SRS. A sample of size 50 isn&#8217;t large enough to estimate grad student opinion with reasonable accuracy. We might prefer a stratified random sample of 200 grad students and 300 undergraduates.</p>
<p id="scc9e-ch04-p-89" block_type="EXP-mid">You know how to select such a stratified sample. Label the graduate students 0001 to 3000 and use <link href="table_a.html">Table A</link> to select an SRS of 200. Then label the undergraduates 00001 to 27000 and use <link href="table_a.html">Table A</link> a second time to select an SRS of 300 of them. These two SRSs together form the stratified sample.</p>
<p id="scc9e-ch04-p-90" block_type="EXP-mid">In the stratified sample, each grad student has chance</p>
<p id="scc9e-ch04-p-91" block_type="EXP-EQ"><phrase data-math="math_2"></phrase></p>
<p id="scc9e-ch04-p-92" block_type="TXT-ni">to be chosen. Each of the undergraduates has a smaller chance,</p>
<p id="scc9e-ch04-p-93" block_type="EXP-EQ"><phrase data-math="math_3"></phrase></p>
<p id="scc9e-ch04-p-94" block_type="EXP-mid">Because we have two SRSs, it is easy to estimate opinions in the two groups separately. The quick and approximate method (<link href="alias:page_46">page 46</link>) tells us that the margin of error for a sample proportion will be about</p>
<p id="scc9e_page_75" block_type="page_start" data-margin-content="right">75</p>
<p id="scc9e-ch04-p-95" block_type="EXP-EQ"><phrase data-math="math_4"></phrase></p>
<p id="scc9e-ch04-p-96" block_type="EXP-mid">for grad students and about</p>
<p id="scc9e-ch04-p-98" block_type="EXP-EQ"><phrase data-math="math_5"></phrase></p>
<p id="scc9e-ch04-p-99" block_type="EXP-mid">for undergraduates.</p>
</box>
<p id="scc9e-ch04-p-100" block_type="TXT">Because the sample in <link href="example_4_8.html">Example 8</link> deliberately overrepresents graduate students, the final analysis must adjust for this to get unbiased estimates of overall student opinion. Remember that our quick method works only for an SRS. In fact, a professional analysis would also take account of the fact that the population contains &#8220;only&#8221; 30,000 individuals&#8212;more job opportunities for statisticians.</p>
<box id="scc9e-ch04-box-17" numbered="false" block_type="BX2">
<p id="scc9e-ch04-p-101" block_type="BX2-H">NOW IT&#8217;S YOUR TURN</p>
<question id="scc9e-ch04-ques-02" block_type="exercise_4_2.html">
<p id="scc9e-ch04-p-102" block_type="BX2-QUE"><phrase block_type="BX2-QUE-N-ri">4.2 A stratified sample.</phrase> The statistics department at Cal Poly, San Luis Obispo, had 18 faculty members and 80 undergraduate majors in 2015. Use the <link href="http://digitalfirst.bfwpub.com/stats_applet/stats_applet_13_srs.html" target="_blank"><em>Simple Random Sample</em> applet</link>, other software, or <link href="table_a.html">Table A</link>, starting at line 111, to choose a stratified sample of one faculty member and one student to attend a reception being held by the university president.</p>
</question>
</box>
<box id="scc9e-ch04-box-18" numbered="false" block_type="margin-statistics">
<p id="scc9e-ch04-p-103" block_type="MN-TXT"><image asset-id="scc9e-ch04-img-06" alt="image" src="asset/global_images/statistics_icon.jpg"/><phrase block_type="MN-T-ri">New York, New York</phrase> New York City, they say, is bigger, richer, faster, ruder. Maybe there&#8217;s something to that. The sample survey firm Zogby International says that as a national average, it takes 5 telephone calls to reach a live person. When calling to New York, it takes 12 calls. Survey firms assign their best interviewers to make calls to New York and often pay them bonuses to cope with the stress.</p>
</box>
<box id="scc9e-ch04-box-19" numbered="false" block_type="EXP" data-filename="example_4_9.html">
<p id="scc9e-ch04-p-104" block_type="EXP-T"><phrase block_type="EXP-N-ri">EXAMPLE 9</phrase> The woes of telephone samples</p>
<p id="scc9e-ch04-p-105" block_type="EXP-first">In principle, it would seem that a telephone survey that dials numbers at random could be based on an SRS. Telephone surveys have little need for clustering. Stratifying can still reduce variability, however, and so telephone surveys often take samples in two stages: a stratified sample of telephone number prefixes (area code plus first three digits) followed by individual numbers (last four digits) dialed at random in each prefix.</p>
<p id="scc9e-ch04-p-106" block_type="EXP-mid">The real problem with an SRS of telephone numbers is that too few numbers lead to households. Blame technology. Fax machines, modems, and cell phones demand new phone numbers. Between 1988 and 2008, the number of households in the United States grew by 29&#37;, but the number of possible residential phone numbers grew by more than 120&#37;. Some analysts believe that, in the near future, we may have to increase the number of digits for telephone numbers from 10 (including the area code) to 12. This will further exacerbate this problem. Telephone surveys now use &#8220;list-assisted samples&#8221; that check electronic telephone directories to eliminate prefixes that have no listed numbers before random sampling begins. Fewer calls are wasted, but anyone living where all numbers are unlisted is missed. Prefixes with no listed numbers are, therefore, separately sampled (stratification again), perhaps with a smaller sample size than if included in the list-assisted sample, to fill the gap.</p>
<p id="scc9e_page_76" block_type="page_start" data-margin-content="left">76</p>
<p id="scc9e-ch04-p-108" block_type="EXP-mid">The proliferation of cell phones has created additional problems for telephone samples. As of December 2013, about 41&#37; of households had cell phones only. Random digit dialing using a machine is not allowed for cell phone numbers. Phone numbers assigned to cell phones are determined by the location of the cell phone company providing the service and need not coincide with the actual residence of the user. This makes it difficult to implement sophisticated methods of sampling such as stratified sampling by geographic location.</p>
</box>
<p id="scc9e-ch04-p-109" block_type="TXT">It may be that the woes of telephone sampling prompted the Gallup Organization, in recent years, to drop the phrase &#8220;random sampling&#8221; from the description of their survey methods at the end of most of their polls. This presumably prevents misinterpreting the results as coming from simple random samples. In the organization&#8217;s detailed description of survey methods used for the Gallup World Poll and the Gallup Well-Being Index (available online at the Gallup website), the samples are described as involving random sampling.</p>
</section>
<section id="scc9e-ch04-sec-08" block_type="h1" chapter="ch4" numbered="false" level="1" print_page="76">
<section-metadata><section-title>The challenge of Internet surveys</section-title></section-metadata>
<p id="scc9e-ch04-p-110" block_type="TXT-ni">The Internet is having a profound effect on many things people do, and this includes surveys. Using the Internet to conduct &#8220;Web surveys&#8221; is becoming increasingly popular. Web surveys have several advantages over more traditional survey methods. It is possible to collect large amounts of survey data at lower costs than traditional methods allow. Anyone can put survey questions on dedicated sites offering free services; thus, large-scale data collection is available to almost every person with access to the Internet. Furthermore, Web surveys allow one to deliver multimedia survey content to respondents, opening up new realms of survey possibilities that would be extremely difficult to implement using traditional methods. Some argue that eventually Web surveys will replace traditional survey methods.</p>
<p id="scc9e-ch04-p-111" block_type="TXT">Although Web surveys are easy to do, they are not easy to do well. The reasons include many of the issues we have discussed in this chapter. Three major problems are voluntary response, undercoverage, and nonresponse. Voluntary response appears in several forms. Some Web surveys invite visitors to a particular website to participate in a poll. Misterpoll.com is one such example. Visitors to this site can participate in several ongoing polls, create their own poll, and respond multiple times to the same poll. Other Web surveys solicit participation through announcements in newsgroups, email invitations, and banner ads on high-traffic sites. An example is a series of 10 polls conducted by Georgia Tech University&#8217;s Graphic, Visualization, and Usability Center (GVU) in the 1990s.</p>
<p id="scc9e_page_77" block_type="page_start" data-margin-content="right">77</p>
<p id="scc9e-ch04-p-113" block_type="TXT">Although misterpoll.com indicates that the surveys on the site are primarily intended for entertainment, the GVU polls appear to claim some measure of legitimacy. The website <link href="http://www.cc.gatech.edu/gvu/user&#95;surveys/">www.cc.gatech.edu/gvu/user&#95;surveys/</link> states that the information from these surveys &#8220;is valued as an independent, objective view of developing Web demographics, culture, user attitudes, and usage patterns.&#8221;</p>
<p id="scc9e-ch04-p-114" block_type="TXT">A third and more sophisticated example of voluntary response occurs when the polling organization creates what it believes to be a representative panel consisting of volunteers and uses panel members as a sampling frame. A random sample is selected from this panel, and those selected are invited to participate in the poll. A very sophisticated version of this approach is used by the Harris Poll Online.</p>
<p id="scc9e-ch04-p-115" block_type="TXT">Web surveys, such as the Harris Poll Online, in which a random sample is selected from a well-defined sampling frame are reasonable when the sampling frame clearly represents some larger population or when interest is only in the members of the sampling frame. An example are Web surveys that use systematic sampling to select every <em>n</em>th visitor to a site and the target population is narrowly defined as visitors to the site. Another example are some Web surveys on college campuses. All students may be assigned email addresses and have Internet access. A list of these email addresses serves as the sampling frame, and a random sample is selected from this list. If the population of interest is all students at this particular college, these surveys can potentially yield very good results. Here is an example of this type of Web survey.</p>
<box id="scc9e-ch04-box-20" numbered="false" block_type="EXP" data-filename="example_4_10.html">
<p id="scc9e-ch04-p-116" block_type="EXP-T"><phrase block_type="EXP-N-ri">EXAMPLE 10</phrase> Doctors and placebos</p>
<p id="scc9e-ch04-p-117" block_type="EXP-first">A placebo is a dummy treatment like a salt pill that has no direct effect on a patient but may bring about a response because patients expect it to. Do academic physicians who maintain private practices sometimes give their patients placebos? A Web survey of doctors in internal medicine departments at Chicago-area medical schools was possible because almost all doctors had listed email addresses.</p>
<p id="scc9e-ch04-p-118" block_type="EXP-mid">An email was sent to each doctor explaining the purpose of the study, promising anonymity, and giving an individual a Web link for response. Result: 45&#37; of respondents said they sometimes use placebos in their clinical practice.</p>
</box>
<p id="scc9e_page_78" block_type="page_start" data-margin-content="left">78</p>
<p id="scc9e-ch04-p-120" block_type="TXT">Several other Web survey methods have been employed to eliminate problems arising from voluntary response. One is to use the Web as one of many alternative ways to participate in the survey. The Bureau of Labor Statistics and the U.S. Census Bureau have used this method. Another method is to select random samples from panels, but instead of relying on volunteers to form the panels, members are recruited using random sampling (for example, random digit dialing). Telephone interviews can be used to collect background information, identify those with Internet access, and recruit eligible persons to the panel. If the target population is current users of the Internet, this method should also potentially yield reliable results. The Pew Research Center has employed this method.</p>
<p id="scc9e-ch04-p-121" block_type="TXT">Perhaps the most ambitious approach, and one that attempts to obtain a random sample from a more general population, is the following. Take a probability sample from the population of interest. Provide all those selected with the necessary equipment and tools to participate in subsequent Web surveys. This methodology is similar in spirit to that used for the Nielsen TV ratings. It was employed by one company, InterSurvey, several years ago, although InterSurvey is no longer in business.</p>
<p id="scc9e-ch04-p-122" block_type="TXT">Several challenges remain for those who employ Web surveys. Even though Internet and email use is growing (according to the 2012 <em>Statistical Abstract of the United States</em>, as of 2010, 80&#37; of American adults aged 18 and older have Internet access at home or work, and 71&#37; have Internet access at home), there is still the problem of undercoverage if Web surveys are used to draw conclusions about all American adults aged 18 and older. Weighting responses to correct for possible biases does not solve the problem because studies indicate that Internet users differ in many ways that traditional methods of weighting do not account for.</p>
<p id="scc9e-ch04-p-123" block_type="TXT">In addition, even if 100&#37; of Americans had Internet access, there is no list of Internet users that we can use as a sampling frame, nor is there anything comparable to random digit dialing that can be used to draw random samples from the collection of all Internet users.</p>
<p id="scc9e-ch04-p-124" block_type="TXT">Finally, Web surveys often have very high rates of nonresponse. Methods that are used in phone and mail surveys to improve response rates can help, but they make Web surveys more expensive and difficult, offsetting some of their advantages.</p>
<p id="scc9e_page_79" block_type="page_start" data-margin-content="right">79</p>
<box id="scc9e-ch04-box-21" numbered="false" block_type="BX3">
<p id="scc9e-ch04-p-125" block_type="BX3-H"><phrase block_type="BX3-H-ri">STATISTICAL</phrase> CONTROVERSIES</p>
<p id="scc9e-ch04-p-126" block_type="BX3-T">The Harris Online Poll</p>
<p id="scc9e-ch04-p-127" block_type="BX3-TXT-ni">The Harris Poll Online has created an online research panel of more than 6 million volunteers. According to the Harris Poll Online website, the &#8220;panel consists of a diverse cross-section of people residing in the United States, as well as in over 200 countries around the world,&#8221; and &#8220;this multimillion member panel consists of potential respondents who have been recruited through online, telephone, mail, and in-person approaches to increase population coverage and enhance representativeness.&#8221; One can join the panel at <link href="http://www.join.harrispollonline.com">join.harrispollonline.com</link>.</p>
<p id="scc9e-ch04-p-129" block_type="BX3-TXT">When the Harris Poll Online conducts a survey, this panel serves as the sampling frame. A probability sample is selected from it, and statistical methods are used to weight the responses. In particular, the Harris Poll Online uses propensity score weighting, a proprietary Harris Interactive technique, which is also applied (when applicable) to adjust for respondents&#8217; likelihood of being online. They claim that &#8220;this procedure provides added assurance of accuracy and representativeness.&#8221;</p>
<figure id="scc9e-ch04-unfig-05" block_type="UN-FIGURE" numbered="false" mmtype="image" mmsrc="" attr="" data-filename="4_17MOORESCC-MSE_9e_P_04_01.html">
<layout align="left" width="medium" border="false"/>
<image asset-id="scc9e-ch04-img-07" alt="image" src="asset/ch4/17MOORESCC-MSE_9e_P_04_01.jpg"/>
<asset_source><phrase block_type="PH-CL">Blend Images/Hill Street Studios/Getty Images</phrase></asset_source>
</figure>
<p id="scc9e-ch04-p-130" block_type="BX3-TXT">Are you convinced that the Harris Poll Online provides accurate information about well-defined populations such as all American adults? Why or why not?</p>
<p id="scc9e-ch04-p-131" block_type="BX3-TXT">For more information about the Harris Poll Online, visit</p>
<p id="scc9e-ch04-p-132" block_type="BX3-URL"><link href="http://www.theharrispoll.com">www.theharrispoll.com</link></p>
<p id="scc9e-ch04-p-133" block_type="BX3-TXT">There is more information in a special issue of <em>Public Opinion Quarterly</em>, available online at <link href="http://poq.oxfordjournals.org/content/72/5.toc">http://poq.oxfordjournals.org/<br/>content/72/5.toc</link></p>
</box>
</section>
<section id="scc9e-ch04-sec-09" block_type="h1" chapter="ch4" numbered="false" level="1" print_page="79">
<section-metadata><section-title>Probability samples</section-title></section-metadata>
<p id="scc9e-ch04-p-135" block_type="TXT-ni">It&#8217;s clear from <link href="example_4_7.html">Examples 7</link>, <link href="example_4_8.html">8</link>, and <link href="example_4_9.html">9</link>, and from the challenges of using the Internet to conduct surveys, that designing samples is a business for experts. Even most statisticians don&#8217;t qualify. We won&#8217;t worry about such details. The big idea is that good sample designs use chance to select individuals from the population. That is, all good samples are <em>probability samples</em>.</p>
<box id="scc9e-ch04-box-22" numbered="false" block_type="BX1">
<p id="scc9e-ch04-p-136" block_type="BX1-T">Probability sample</p>
<p id="scc9e-ch04-p-137" block_type="BX1-TXT-ni">A <strong>probability sample</strong> is a sample chosen by chance. We must know what samples are possible and what chance, or probability, each possible sample has.</p>
<p id="scc9e-ch04-p-138" block_type="BX1-TXT-ni">Some probability samples, such as stratified samples, don&#8217;t allow all possible samples from the population and may not give an equal chance to all the samples they do allow. As such, not all probability samples are random samples.</p>
</box>
<p id="scc9e_page_80" block_type="page_start" data-margin-content="left">80</p>
<p id="scc9e-ch04-p-140" block_type="TXT-ni">A stratified sample of 300 undergraduate students and 200 graduate students, for example, allows only samples with exactly that makeup. An SRS would allow any 500 students. Both are probability samples. We need only know that estimates from any probability sample share the nice properties of estimates from an SRS. Confidence statements can be made without bias and have smaller margins of error as the size of the sample increases. Nonprobability samples such as voluntary response samples do not share these advantages and cannot give trustworthy information about a population. Now that we know that most nationwide samples are more complicated than an SRS, we will usually go back to acting as if good samples were SRSs. That keeps the big idea and hides the messy details.</p>
</section>
<section id="scc9e-ch04-sec-10" block_type="h1" chapter="ch4" numbered="false" level="1" print_page="80">
<section-metadata><section-title>Questions to ask before you believe a poll</section-title></section-metadata>
<p id="scc9e-ch04-p-141" block_type="TXT-ni">Opinion polls and other sample surveys can produce accurate and useful information if the pollster uses good statistical techniques and also works hard at preparing a sampling frame, wording questions, and reducing nonresponse. Many surveys, however, especially those designed to influence public opinion rather than just record it, do not produce accurate or useful information. Here are some questions to ask before you pay much attention to poll results.</p>
<list id="scc9e-ch04-list-01" type="unordered" block_type="bluebullet">
<li id="scc9e-ch04-li-01"><p id="scc9e-ch04-p-142" block_type="BL-first"><phrase block_type="maker">&#8226;</phrase> <strong>Who carried out the survey?</strong> Even a political party should hire a professional sample survey firm whose reputation demands that it follow good survey practices.</p></li>
<li id="scc9e-ch04-li-02"><p id="scc9e-ch04-p-143" block_type="BL-last"><phrase block_type="maker">&#8226;</phrase> <strong>What was the population?</strong> That is, whose opinions were being sought?</p></li>
<li id="scc9e-ch04-li-03"><p id="scc9e-ch04-p-144" block_type="BL-first"><phrase block_type="maker">&#8226;</phrase> <strong>How was the sample selected?</strong> Look for mention of random sampling.</p></li>
<li id="scc9e-ch04-li-04"><p id="scc9e-ch04-p-145" block_type="BL-first"><phrase block_type="maker">&#8226;</phrase> <strong>How large was the sample?</strong> Even better, find out both the sample size and the <strong>margin of error</strong> within which the results of 95&#37; of all samples drawn as this one was would fall.</p></li>
<li id="scc9e-ch04-li-05"><p id="scc9e-ch04-p-146" block_type="BL-first"><phrase block_type="maker">&#8226;</phrase> <strong>What was the response rate?</strong> That is, what percentage of the original subjects actually provided information?</p></li>
<li id="scc9e-ch04-li-06"><p id="scc9e-ch04-p-147" block_type="BL-first"><phrase block_type="maker">&#8226;</phrase> <strong>How were the subjects contacted?</strong> By telephone? Mail? Face-to-face interview?</p></li>
<li id="scc9e-ch04-li-07"><p id="scc9e-ch04-p-148" block_type="BL-first"><phrase block_type="maker">&#8226;</phrase> <strong>When was the survey conducted?</strong> Was it just after some event that might have influenced opinion?</p></li>
<li id="scc9e-ch04-li-08"><p id="scc9e-ch04-p-149" block_type="BL-last"><phrase block_type="maker">&#8226;</phrase> <strong>What were the exact questions asked?</strong></p></li>
</list>
<p id="scc9e_page_81" block_type="page_start" data-margin-content="right">81</p>
<p id="scc9e-ch04-p-151" block_type="TXT-ni">Academic survey centers and government statistical offices answer these questions when they announce the results of a sample survey. National opinion polls usually don&#8217;t announce their response rate (which is often low) but do give us the other information. Editors and newscasters have the bad habit of cutting out these dull facts and reporting only the sample results. Many sample surveys by interest groups and local newspapers and TV stations don&#8217;t answer these questions because their polling methods are, in fact, unreliable. If a politician, an advertiser, or your local TV station announces the results of a poll without complete information, be skeptical.</p>
</section>
<section id="scc9e-ch04-sec-11" block_type="SUM-H" chapter="ch4" numbered="false" level="1" print_page="81">
<section-metadata><section-title><phrase block_type="SUM-H-ri"><strong>STATISTICS</strong> IN SUMMARY</phrase></section-title></section-metadata>
<p id="scc9e-ch04-p-152" block_type="SUM-hd1">Chapter Specifics</p>
<list id="scc9e-ch04-list-02" type="unordered" block_type="bluebullet">
<li id="scc9e-ch04-li-09"><p id="scc9e-ch04-p-153" block_type="SUM-BL-first"><phrase block_type="maker">&#8226;</phrase> Sampling in the real world is complex. Even professional sample surveys don&#8217;t give exactly correct information about the population.</p></li>
<li id="scc9e-ch04-li-10"><p id="scc9e-ch04-p-154" block_type="SUM-BL-mid"><phrase block_type="maker">&#8226;</phrase> There are many potential sources of error in sampling. The margin of error announced by a sample survey covers only <strong>random sampling error</strong>, the variation due to chance in choosing a random sample.</p></li>
<li id="scc9e-ch04-li-11"><p id="scc9e-ch04-p-155" block_type="SUM-BL-mid"><phrase block_type="maker">&#8226;</phrase> Other types of error are in addition to the margin of error and can&#8217;t be directly measured. <strong>Sampling errors</strong> come from the act of choosing a sample. Random sampling error and <strong>undercoverage</strong> are common types of sampling error. Undercoverage occurs when some members of the population are left out of the <strong>sampling frame</strong>, the list from which the sample is actually chosen.</p></li>
<li id="scc9e-ch04-li-12"><p id="scc9e-ch04-p-156" block_type="SUM-BL-mid"><phrase block_type="maker">&#8226;</phrase> The most serious errors in most careful surveys, however, are <strong>nonsampling errors</strong>. These have nothing to do with choosing a sample&#8212;they are present even in a census.</p></li>
<li id="scc9e-ch04-li-13"><p id="scc9e-ch04-p-157" block_type="SUM-BL-mid"><phrase block_type="maker">&#8226;</phrase> The single biggest problem for sample surveys is <strong>nonresponse</strong>: subjects can&#8217;t be contacted or refuse to answer.</p></li>
<li id="scc9e-ch04-li-14"><p id="scc9e-ch04-p-158" block_type="SUM-BL-mid"><phrase block_type="maker">&#8226;</phrase> Mistakes in handling the data (<strong>processing errors</strong>) and incorrect answers by respondents (<strong>response errors</strong>) are other examples of nonsampling errors.</p></li>
<li id="scc9e-ch04-li-15"><p id="scc9e-ch04-p-159" block_type="SUM-BL-mid"><phrase block_type="maker">&#8226;</phrase> Finally, the exact <strong>wording of questions</strong> has a big influence on the answers.</p></li>
<li id="scc9e-ch04-li-16"><p id="scc9e-ch04-p-160" block_type="SUM-BL-mid"><phrase block_type="maker">&#8226;</phrase> People who design sample surveys use statistical techniques that help correct nonsampling errors, and they also use <strong>probability samples</strong> more complex than simple random samples, such as <strong>stratified samples</strong>.</p>
<p id="scc9e_page_82" block_type="page_start" data-margin-content="left">82</p></li>
<li id="scc9e-ch04-li-17"><p id="scc9e-ch04-p-162" block_type="SUM-BL-mid"><phrase block_type="maker">&#8226;</phrase> You can assess the quality of a sample survey quite well by just looking at the basics: use of random samples, sample size and margin of error, the rate of nonresponse, and the wording of the questions.</p></li>
</list>
<p id="scc9e-ch04-p-163" block_type="SUM-TXT-ni">
<image asset-id="scc9e-ch04-img-08" alt="image" src="asset/global_images/LinkIt.jpg"/>In <link href="scc9e-ch04.xml">Chapter 3</link>, we saw that random samples can provide a sound basis for drawing conclusions about a population parameter. In this chapter, we learned that even when we take a random sample, our conclusions can be weakened by undercoverage, processing errors, response errors, nonresponse, and wording of questions. We must pay careful attention to every aspect of how we collect data to ensure that the conclusions we make are valid. In some cases, more complex probability samples, such as stratified samples, can help correct nonsampling errors. This chapter provides a list of questions you can ask to help you assess the quality of the results of samples collected by someone else.
</p>

<box id="scc9e-ch04-box-23" numbered="false" block_type="case_title">
<p id="scc9e-ch04-p-164" block_type="BX4-TXT-first"><phrase block_type="BX4-H-ri"><strong>CASE STUDY</strong> EVALUATED</phrase> Use what you have learned in this chapter to evaluate the Case Study that opened the chapter. In particular, do the following.</p>
<list id="scc9e-ch04-list-03" type="ordered" block_type="numbered">
<li id="scc9e-ch04-li-18"><p id="scc9e-ch04-p-165" block_type="BX4-TXT-I"><phrase block_type="maker">1.</phrase> Answer the questions given in the section &#8220;Questions to Ask before You Believe a Poll&#8221; on <link href="alias:page_80">page 80</link>.</p></li>
<li id="scc9e-ch04-li-19"><p id="scc9e-ch04-p-166" block_type="BX4-TXT-I"><phrase block_type="maker">2.</phrase> Are the results of the Pew poll useless? You may want to refer to the discussion on <link href="alias:page_76">pages 76</link>&#8211;<link href="alias:page_79">79</link>.</p></li>
</list>
</box>
<box id="scc9e-ch04-box-24" numbered="false" block_type="launchpad">
<p id="scc9e-ch04-p-167" block_type="CR-BIB-T">
<image asset-id="scc9e-ch04-img-09" alt="image" src="asset/global_images/launchpad_ML_logo_cmyk.jpg"/> Online Resources</p>
<list id="scc9e-ch04-list-04" type="unordered" block_type="redbullet">
<li id="scc9e-ch04-li-20"><p id="scc9e-ch04-p-168" block_type="CR-BIB-BL-first"><phrase block_type="maker">&#8226;</phrase> The video technology manuals explain how to select an SRS using <link href="http://www.whfreeman.com/BrainHoney/Resource/6710/SitebuilderUploads/shared_resources/videos/VTMs/Excel/Excel_vtm_Sampling_from_a_Data_Set.html" target="_blank">Excel</link>, <link href="http://www.whfreeman.com/BrainHoney/Resource/6710/SitebuilderUploads/shared_resources/videos/VTMs/JMP/JMP_vtm_Sampling_from_a_Data_Set.html" target="_blank">JMP</link>, <link href="http://www.whfreeman.com/BrainHoney/Resource/6710/SitebuilderUploads/shared_resources/videos/VTMs/Minitab/Minitab_vtm_Sampling_from_a_data_set.html" target="_blank">Minitab</link>, and the <link href="http://www.whfreeman.com/BrainHoney/Resource/6710/SitebuilderUploads/shared_resources/videos/VTMs/TI/TI_vtm_Sampling_from_a_Data_Set.html" target="_blank">TI 83/84</link>.</p></li>
<li id="scc9e-ch04-li-21"><p id="scc9e-ch04-p-169" block_type="CR-BIB-BL-last"><phrase block_type="maker">&#8226;</phrase><link href="http://digitalfirst.bfwpub.com/stats_applet/stats_applet_13_srs.html" target="_blank"> The Statistical Applet <em>Simple Random Sample</em></link> can be used to select a simple random sample when the number of labels is 144 or fewer.</p></li>
</list>
</box>
</section>
<section id="scc9e-ch04-sec-12" block_type="CR-X-H" chapter="ch4" numbered="false" level="1" print_page="82">
<section-metadata><section-title>CHECK THE BASICS</section-title></section-metadata>
<p id="scc9e-ch04-p-170" block_type="CR-X"><em>For <link href="exercise_4_1.html">Exercise 4.1</link>, see page 72; for <link href="exercise_4_2.html">Exercise 4.2</link>, see page 75.</em></p>
<question id="scc9e-ch04-ques-03" block_type="exercise_4_3.html">
<p id="scc9e-ch04-p-171" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.3 What does the margin of error include?</phrase> When a margin of error is reported for a survey, it includes</p>
<list id="scc9e-ch04-list-05" type="ordered" block_type="lower-alpha">
<li id="scc9e-ch04-li-22"><p id="scc9e-ch04-p-172" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(a)</phrase> random sampling error and other practical difficulties like undercoverage and nonresponse.</p></li>
<li id="scc9e-ch04-li-23"><p id="scc9e-ch04-p-173" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(b)</phrase> random sampling error, but not other practical difficulties like undercoverage and nonresponse.</p></li>
<li id="scc9e-ch04-li-24"><p id="scc9e-ch04-p-174" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(c)</phrase> practical difficulties like undercoverage and nonresponse, but not random sampling error.</p></li>
<li id="scc9e-ch04-li-25"><p id="scc9e-ch04-p-175" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(d)</phrase> None of the above is correct.</p></li>
</list>
</question>
<p id="scc9e_page_83" block_type="page_start" data-margin-content="right">83</p>
<question id="scc9e-ch04-ques-04" block_type="exercise_4_4.html">
<p id="scc9e-ch04-p-177" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.4 What kind of sample?</phrase> Archaeologists plan to examine a sample of two-meter-square plots near an ancient Greek city for artifacts visible in the ground. They choose separate samples of plots from floodplain, coast, foothills, and high hills. What kind of sample is this?</p>
<list id="scc9e-ch04-list-06" type="ordered" block_type="lower-alpha">
<li id="scc9e-ch04-li-26"><p id="scc9e-ch04-p-178" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(a)</phrase> A simple random sample</p></li>
<li id="scc9e-ch04-li-27"><p id="scc9e-ch04-p-179" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(b)</phrase> A voluntary response sample</p></li>
<li id="scc9e-ch04-li-28"><p id="scc9e-ch04-p-180" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(c)</phrase> A stratified sample</p></li>
<li id="scc9e-ch04-li-29"><p id="scc9e-ch04-p-181" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(d)</phrase> A cluster sample</p></li>
</list>
</question>
<question id="scc9e-ch04-ques-05" block_type="exercise_4_5.html">
<p id="scc9e-ch04-p-182" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.5 Sampling issues.</phrase> A sample of households in a community is selected at random from the telephone directory. In this community, 4&#37; of households have no telephone, 10&#37; have only cell phones, and another 25&#37; have unlisted telephone numbers. The sample will certainly suffer from</p>
<list id="scc9e-ch04-list-07" type="ordered" block_type="lower-alpha">
<li id="scc9e-ch04-li-30"><p id="scc9e-ch04-p-183" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(a)</phrase> nonresponse.</p></li>
<li id="scc9e-ch04-li-31"><p id="scc9e-ch04-p-184" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(b)</phrase> undercoverage.</p></li>
<li id="scc9e-ch04-li-32"><p id="scc9e-ch04-p-185" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(c)</phrase> false responses.</p></li>
<li id="scc9e-ch04-li-33"><p id="scc9e-ch04-p-186" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(d)</phrase> all of the above.</p></li>
</list>
</question>
<question id="scc9e-ch04-ques-06" block_type="exercise_4_6.html">
<p id="scc9e-ch04-p-187" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.6 Question wording.</phrase> Which of the following represents wording that will most likely <em>not</em> influence the answers?</p>
<list id="scc9e-ch04-list-08" type="ordered" block_type="lower-alpha">
<li id="scc9e-ch04-li-34"><p id="scc9e-ch04-p-188" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(a)</phrase> Do you think that all instances of academic misconduct should be reported to the dean?</p></li>
<li id="scc9e-ch04-li-35"><p id="scc9e-ch04-p-189" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(b)</phrase> Academic misconduct undermines the integrity of the university and education in general. Do you believe that all instances of academic misconduct should be reported to the dean?</p></li>
<li id="scc9e-ch04-li-36"><p id="scc9e-ch04-p-190" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(c)</phrase> Academic misconduct can range from something as minor as using one&#8217;s own work in two courses to major issues like cheating on exams and plagiarizing. Do you believe that all instances of academic misconduct should be reported to the dean?</p></li>
<li id="scc9e-ch04-li-37"><p id="scc9e-ch04-p-191" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(d)</phrase> None of the above will influence the answers.</p></li>
</list>
</question>
<question id="scc9e-ch04-ques-07" block_type="exercise_4_7.html">
<p id="scc9e-ch04-p-192" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.7 Sampling considerations.</phrase> A statistics class has 10 graduate students and 40 undergraduate students. You want to randomly sample 10&#37; of the students in the class. One graduate student and four undergraduate students are selected at random. Which of the following is <em>not</em> correct?</p>
<list id="scc9e-ch04-list-09" type="ordered" block_type="lower-alpha">
<li id="scc9e-ch04-li-38"><p id="scc9e-ch04-p-193" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(a)</phrase> Because each student has a 10&#37; chance of being selected, this is a simple random sample.</p></li>
<li id="scc9e-ch04-li-39"><p id="scc9e-ch04-p-194" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(b)</phrase> Because each sample includes exactly one graduate student and four undergraduate students, this is not a random sample.</p></li>
<li id="scc9e-ch04-li-40"><p id="scc9e-ch04-p-195" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(c)</phrase> It is possible to get a sample that contains only graduate students.</p></li>
<li id="scc9e-ch04-li-41"><p id="scc9e-ch04-p-196" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(d)</phrase> It is possible to get a sample that contains only undergraduate students.</p></li>
</list>
</question>
</section>
<section id="scc9e-ch04-sec-13" block_type="CR-X-H-v1" chapter="ch4" numbered="false" level="1" print_page="83">
<section-metadata><section-title>CHAPTER 4 EXERCISES</section-title></section-metadata>
<question id="scc9e-ch04-ques-08" block_type="exercise_4_8.html">
<p id="scc9e-ch04-p-197" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.8 What kind of error?</phrase> Which of the following are sources of <em>sampling error</em> and which are sources of <em>nonsampling error</em>? Explain your answers.</p>
<list id="scc9e-ch04-list-10" type="ordered" block_type="lower-alpha">
<li id="scc9e-ch04-li-42"><p id="scc9e-ch04-p-198" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(a)</phrase> The subject lies about past drug use.</p></li>
<li id="scc9e-ch04-li-43"><p id="scc9e-ch04-p-199" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(b)</phrase> A typing error is made in recording the data.</p></li>
<li id="scc9e-ch04-li-44"><p id="scc9e-ch04-p-201" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(c)</phrase> Data are gathered by asking people to go to a website and answer questions online.</p></li>
</list>
</question>
<p id="scc9e_page_84" block_type="page_start" data-margin-content="left">84</p>
<question id="scc9e-ch04-ques-09" block_type="exercise_4_9.html">
<p id="scc9e-ch04-p-202" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.9 What kind of error?</phrase> Each of the following is a source of error in a sample survey. Label each as <em>sampling error</em> or <em>nonsampling error</em>, and explain your answers.</p>
<list id="scc9e-ch04-list-11" type="ordered" block_type="lower-alpha">
<li id="scc9e-ch04-li-45"><p id="scc9e-ch04-p-203" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(a)</phrase> The telephone directory is used as a sampling frame.</p></li>
<li id="scc9e-ch04-li-46"><p id="scc9e-ch04-p-204" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(b)</phrase> The subject cannot be contacted in five calls.</p></li>
<li id="scc9e-ch04-li-47"><p id="scc9e-ch04-p-205" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(c)</phrase> Interviewers choose people on the street to interview.</p></li>
</list>
</question>
<question id="scc9e-ch04-ques-10" block_type="exercise_4_10.html">
<p id="scc9e-ch04-p-206" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.10 Not in the margin of error.</phrase> According to a February 2008 <em>USA Today</em>/Gallup Poll, 43&#37; of Americans identify themselves as baseball fans. That is low by recent standards, as an average of 49&#37; of Americans have said they were fans of the sport since Gallup started tracking this measure in 1993. The high point came in 1998, when Sammy Sosa and Mark McGwire pursued (and ultimately surpassed) Roger Maris&#8217;s single-season home run record, at which time 56&#37; of Americans considered themselves baseball fans. The Gallup press release says:</p>
<p id="scc9e-ch04-p-207" block_type="CR-X-NL-EXT"><em>For results based on this sample, one can say with 95&#37; confidence that the maximum error attributable to sampling and other random effects is &#177;5 percentage points.</em></p>
<p id="scc9e-ch04-p-208" block_type="CR-X-NL">Give one example of a source of error in the poll result that is <em>not</em> included in this margin of error.</p>
</question>
<question id="scc9e-ch04-ques-11" block_type="exercise_4_11.html">
<p id="scc9e-ch04-p-209" block_type="CR-X-NL"><image asset-id="scc9e-ch04-img-news1" alt="image" src="asset/global_images/news.jpg"/>
<phrase block_type="CR-X-NL-N-ri">4.11 Not in the margin of error.</phrase> According to a June 2015 Gallup Poll, more American adults ages 18 to 29 report being single and never married&#8212;the percentage has risen from 52&#37; in 2004 to 64&#37; in 2014. For American adults aged 30 to 39, this same percentage has risen modestly from 15&#37; in 2004 to 19&#37; in 2014. The Gallup press release says:</p>
<p id="scc9e-ch04-p-210" block_type="CR-X-NL-EXT"><em>For results based on the total sample of Americans ages 18 to 29 or 30 to 39 in any given year, the maximum margin of sampling error is &#177;3 percentage points at the 95&#37; confidence level.</em></p>
<p id="scc9e-ch04-p-211" block_type="CR-X-NL">Give one example of a source of error in the poll result that is <em>not</em> included in this margin of error.</p>
</question>
<question id="scc9e-ch04-ques-12" block_type="exercise_4_12.html">
<p id="scc9e-ch04-p-212" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.12 College parents.</phrase> An online survey of college parents was conducted during February and March 2007. An email was sent to 41,000 parents who were listed in either the College Parents of America database or the Student Advantage database. Parents were invited to participate in the online survey. Out of those invited, 1727 completed the online survey. The survey protected the anonymity of those participating in the survey but did not allow more than one response from an individual IP address.</p>
<p id="scc9e-ch04-p-213" block_type="CR-X-NL">One of the survey results was that 33&#37; of mothers communicate at least once a day with their child while at school.</p>
<list id="scc9e-ch04-list-12" type="ordered" block_type="lower-alpha">
<li id="scc9e-ch04-li-48"><p id="scc9e-ch04-p-214" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(a)</phrase> What was the <em>response rate</em> for this survey? (The response rate is the percentage of the planned sample&#8212; that is, those invited to participate&#8212;who responded.)</p></li>
<li id="scc9e-ch04-li-49"><p id="scc9e-ch04-p-215" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(b)</phrase> Use the quick method (<link href="alias:page_46">page 46</link>) to estimate the margin of error for a random sample of size 1727.</p></li>
<li id="scc9e-ch04-li-50"><p id="scc9e-ch04-p-217" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(c)</phrase> Do you think that the margin of error is a good measure of the accuracy of the survey&#8217;s results? Explain your answer.</p></li>
</list>
</question>
<p id="scc9e_page_85" block_type="page_start" data-margin-content="right">85</p>
<question id="scc9e-ch04-ques-13" block_type="exercise_4_13.html">
<p id="scc9e-ch04-p-218" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.13 Polling customers.</phrase> An online store chooses an SRS of 100 customers from its list of all people who have bought something from the store in the last year. It asks those selected how satisfied they are with the store&#8217;s website. If it selected two SRSs of 100 customers at the same time, the two samples would give somewhat different results. Is this variation a source of sampling error or of nonsampling error? Would the survey&#8217;s announced margin of error take this source of error into account?</p>
</question>
<question id="scc9e-ch04-ques-14" block_type="exercise_4_14.html">
<p id="scc9e-ch04-p-219" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.14 Ring-no-answer.</phrase> A common form of nonresponse in telephone surveys is &#8220;ring-no-answer.&#8221; That is, a call is made to an active number but no one answers. The Italian National Statistical Institute looked at nonresponse to a government survey of households in Italy during the periods January 1 to Easter and July 1 to August 31. All calls were made between 7 and 10 <phrase block_type="small">P.M.</phrase>, but 21.4&#37; gave &#8220;ring-noanswer&#8221; in one period versus 41.5&#37; &#8220;ring-no-answer&#8221; in the other period. Which period do you think had the higher rate of no answers? Why? Explain why a high rate of nonresponse makes sample results less reliable.</p>
</question>
<question id="scc9e-ch04-ques-15" block_type="exercise_4_15.html">
<p id="scc9e-ch04-p-220" block_type="CR-X-NL"><image asset-id="scc9e-ch04-img-news2" alt="image" src="asset/global_images/news.jpg"/>
<phrase block_type="CR-X-NL-N-ri">4.15 Race relations.</phrase> Here are two opinion poll questions asked about race relations in the United States.</p>
<p id="scc9e-ch04-p-221" block_type="CR-X-NL-EXT"><em>We&#8217;d like to know how you would rate relations between various groups in the United States these days. Would you say relations between whites and blacks are very good, somewhat good, somewhat bad, or very bad?</em></p>
<p id="scc9e-ch04-p-222" block_type="CR-X-NL-EXT"><em>Do you think race relations in the U.S. are generally good or generally bad?</em></p>
<p id="scc9e-ch04-p-223" block_type="CR-X-NL">In response to the first question, 72&#37; of non-Hispanic whites and 66&#37; of blacks answered relations between blacks and whites are &#8220;very good&#8221; or &#8220;somewhat good.&#8221; Sixty-one percent (61&#37;) of those answering the second question responded &#8220;generally bad.&#8221;</p>
<p id="scc9e-ch04-p-224" block_type="CR-X-NL">The first question came from a poll that was conducted in March 2015. The second question came from a poll that was conducted between April 30 and May 3 of that same year. Between the two polls, a man named Freddie Gray died after being in the custody of the Baltimore police. In what ways do you think this event may have affected the responses to the two different polls? Do you think the results would be different if the question from the second poll had been worded like the question from the first poll?</p>
</question>
<question id="scc9e-ch04-ques-16" block_type="exercise_4_16.html">
<p id="scc9e-ch04-p-225" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.16 The environment and the economy.</phrase> Here are two opinion poll questions asked in December 2009 about protecting the environment versus protecting the economy.</p>
<p id="scc9e-ch04-p-226" block_type="CR-X-NL-EXT"><em>Often there are trade-offs or sacrifices people must make in deciding what is important to them. Generally speaking, when a trade-off has to be made, which is more important to you: stimulating the economy or protecting the environment?</em></p>
<p id="scc9e-ch04-p-228" block_type="CR-X-NL-EXT"><em>Which worries you more: that the U.S. will NOT take the actions necessary to prevent the catastrophic effects of global warming because of fears those actions would harm the economy or that the U.S. WILL take actions to protect against global warming and those actions will cripple the U.S. economy?</em></p>
<p id="scc9e-ch04-p-229" block_type="CR-X-NL">In response to the first question, 61&#37; said stimulating the economy was more important. But only 46&#37; of those asked the second question said they were afraid that the United States will take actions to protect against global warming and that those actions will cripple the U.S. economy. Why do you think the second wording discouraged more people from expressing more concern about the economy than about the environment?</p>
</question>
<p id="scc9e_page_86" block_type="page_start" data-margin-content="left">86</p>
<question id="scc9e-ch04-ques-17" block_type="exercise_4_17.html">
<p id="scc9e-ch04-p-230" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.17 Amending the Constitution.</phrase> You are writing an opinion poll question about a proposed amendment to the Constitution. You can ask if people are in favor of &#8220;changing the Constitution&#8221; or &#8220;adding to the Constitution&#8221; by approving the amendment.</p>
<list id="scc9e-ch04-list-13" type="ordered" block_type="lower-alpha">
<li id="scc9e-ch04-li-51"><p id="scc9e-ch04-p-231" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(a)</phrase> Why do you think the responses to these two questions will produce different percentages in favor?</p></li>
<li id="scc9e-ch04-li-52"><p id="scc9e-ch04-p-232" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(b)</phrase> One of these choices of wording will produce a much higher percentage in favor. Which one? Why?</p></li>
</list>
</question>
<question id="scc9e-ch04-ques-18" block_type="exercise_4_18.html">
<p id="scc9e-ch04-p-233" block_type="CR-X-NL"><image asset-id="scc9e-ch04-img-news3" alt="image" src="asset/global_images/news.jpg"/>
<phrase block_type="CR-X-NL-N-ri">4.18 Right to refuse services.</phrase> The Supreme Court of the United States released a ruling on same-sex marriage in June 2015. Prior to the release of this ruling, many agencies conducted polls about same-sex marriage. In April 2015, a Quinnipiac University poll asked two questions about businesses and services to gays and lesbians. Here are the two questions:</p>
<p id="scc9e-ch04-p-234" block_type="CR-X-NL-EXT"><em>Do you think businesses should or should not be allowed to refuse services to gays and lesbians?</em></p>
<p id="scc9e-ch04-p-235" block_type="CR-X-NL-EXT"><em>What if the business says homosexuality violates its owners&#8217; religious beliefs? In that case, do you think the business should or should not be allowed to refuse services to gays and lesbians?</em></p>
<p id="scc9e-ch04-p-236" block_type="CR-X-NL">One of these questions drew 35&#37; saying the businesses should be allowed to refuse services; the other drew 26&#37; with the same response. Which wording produced the higher percentage? Why?</p>
</question>
<question id="scc9e-ch04-ques-19" block_type="exercise_4_19.html">
<p id="scc9e-ch04-p-237" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.19 Wording survey questions.</phrase> Comment on each of the following as a potential sample survey question. Is the question clear? Is it slanted toward a desired response? (Survey questions on issues that one might regard as inflammatory are often prone to slanted wording.)</p>
<list id="scc9e-ch04-list-14" type="ordered" block_type="lower-alpha">
<li id="scc9e-ch04-li-53"><p id="scc9e-ch04-p-238" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(a)</phrase> Which of the following best represents your opinion on gun control?</p>
<list id="scc9e-ch04-list-15" type="ordered" block_type="numbered">
<li id="scc9e-ch04-li-54"><p id="scc9e-ch04-p-239" block_type="cr-x-nl-lvl3"><phrase block_type="maker">1.</phrase> The government should take away our guns.</p></li>
<li id="scc9e-ch04-li-55"><p id="scc9e-ch04-p-240" block_type="cr-x-nl-lvl3"><phrase block_type="maker">2.</phrase> We have the right to keep and bear arms.</p></li>
</list></li>
<li id="scc9e-ch04-li-56"><p id="scc9e-ch04-p-241" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(b)</phrase> In light of skyrocketing gasoline prices, we should consider opening up a very small amount of Alaskan wilderness for oil exploration as a way of reducing our dependence on foreign oil. Do you agree or disagree?</p></li>
<li id="scc9e-ch04-li-57"><p id="scc9e-ch04-p-243" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(c)</phrase> Do you think that the excessive restrictions placed on U.S. law enforcement agencies hampered their ability to detect the 9/11 terrorist plot before it occurred?</p></li>
<li id="scc9e-ch04-li-58"><p id="scc9e-ch04-p-244" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(d)</phrase> Do you use drugs?</p></li>
</list>
</question>
<p id="scc9e_page_87" block_type="page_start" data-margin-content="right">87</p>
<question id="scc9e-ch04-ques-20" block_type="exercise_4_20.html">
<p id="scc9e-ch04-p-245" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.20 Bad survey questions.</phrase> Write your own examples of bad sample survey questions.</p>
<list id="scc9e-ch04-list-16" type="ordered" block_type="lower-alpha">
<li id="scc9e-ch04-li-59"><p id="scc9e-ch04-p-246" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(a)</phrase> Write a biased question designed to get one answer rather than another.</p></li>
<li id="scc9e-ch04-li-60"><p id="scc9e-ch04-p-247" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(b)</phrase> Write a question that is confusing so that it is hard to answer.</p></li>
</list>
</question>
<question id="scc9e-ch04-ques-21" block_type="exercise_4_21.html">
<p id="scc9e-ch04-p-248" block_type="CR-X-NL"><image asset-id="scc9e-ch04-img-news4" alt="image" src="asset/global_images/news.jpg"/>
<phrase block_type="CR-X-NL-N-ri">4.21 Appraising a poll.</phrase> In January 2015, <em>The Wall Street Journal</em> published an article on satisfaction with the U.S. economy and other issues. The article noted 45&#37; of Americans were very or somewhat satisfied with the state of the U.S. economy, even though 49&#37; felt America is in a state of decline. News articles tend to be brief in describing sample surveys. Here is part of <em>The Wall Street Journal</em>&#8217;s description of this poll:</p>
<p id="scc9e-ch04-p-249" block_type="CR-X-NL-EXT"><em>The . . . poll was based on nationwide telephone interviews of 800 adults, including 280 respondents who use only a cellphone. . . . Individuals were selected proportionate to the nation&#8217;s population in accordance with a probability sample. . . . The data&#8217;s margin of error is plus or minus 3.46 percentage points.</em></p>
<p id="scc9e-ch04-p-250" block_type="CR-X-NL"><link href="alias:page_80">Page 80</link> lists several &#8220;questions to ask&#8221; about an opinion poll. What answers does <em>The Wall Street Journal</em> give to each of these questions?</p>
</question>
<question id="scc9e-ch04-ques-22" block_type="exercise_4_22.html">
<p id="scc9e-ch04-p-251" block_type="CR-X-NL"><image asset-id="scc9e-ch04-img-news5" alt="image" src="asset/global_images/news.jpg"/>
<phrase block_type="CR-X-NL-N-ri">4.22 Appraising a poll.</phrase> A June 2015 <em>New York Times</em> article about the inequality of wealth and income discussed the results of a sample survey that found, for example, that 67&#37; of those surveyed think the gap between the rich and the poor in the United States is getting larger. Here is part of the <em>Times</em>&#8217;s statement &#8220;How the Poll Was Conducted&#8221;:</p>
<p id="scc9e-ch04-p-252" block_type="CR-X-NL-EXT"><em>The latest New York Times/CBS News Poll is based on telephone interviews conducted May 28 to 31 with 1,022 adults throughout the United States . . .</em></p>
<p id="scc9e-ch04-p-253" block_type="CR-X-NL-EXT"><em>The sample of land-line telephone exchanges called was randomly selected by a computer . . .</em></p>
<p id="scc9e-ch04-p-254" block_type="CR-X-NL">The <em>Times</em>&#8217;s statement goes on to say that cell phone numbers were also randomly selected by a computer and that the samples of landline and cell phone responses were combined and appropriately adjusted. <link href="alias:page_80">Page 80</link> lists several &#8220;questions to ask&#8221; about an opinion poll. What answers does the <em>Times</em> give to each of these questions?</p>
</question>
<question id="scc9e-ch04-ques-23" block_type="exercise_4_23.html">
<p id="scc9e-ch04-p-255" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.23 Closed versus open questions.</phrase> Two basic types of questions are closed questions and open questions. A closed question asks the subject for one or more of a fixed set of responses. An open question allows the subject to answer in his or her own words; the interviewer writes down the responses and classifies them later. An example of an open question is</p>
<p id="scc9e-ch04-p-256" block_type="CR-X-NL-EXT"><em>What do you believe about the afterlife?</em></p>
<p id="scc9e-ch04-p-258" block_type="CR-X-NL">An example of a closed question is</p>
<p id="scc9e-ch04-p-259" block_type="CR-X-NL-EXT"><em>What do you believe about the afterlife? Do you believe</em></p>
<list id="scc9e-ch04-list-17" type="ordered" block_type="lower-alpha">
<li id="scc9e-ch04-li-61"><p id="scc9e-ch04-p-260" block_type="CR-X-NL-EXT"><em><phrase block_type="maker">a.</phrase> there is an afterlife and entrance depends only on your actions?</em></p></li>
<li id="scc9e-ch04-li-62"><p id="scc9e-ch04-p-261" block_type="CR-X-NL-EXT"><em><phrase block_type="maker">b.</phrase> there is an afterlife and entrance depends only on your beliefs?</em></p></li>
<li id="scc9e-ch04-li-63"><p id="scc9e-ch04-p-262" block_type="CR-X-NL-EXT"><em><phrase block_type="maker">c.</phrase> there is an afterlife and everyone lives there forever?</em></p></li>
<li id="scc9e-ch04-li-64"><p id="scc9e-ch04-p-263" block_type="CR-X-NL-EXT"><em><phrase block_type="maker">d.</phrase> there is no afterlife?</em></p></li>
<li id="scc9e-ch04-li-65"><p id="scc9e-ch04-p-264" block_type="CR-X-NL-EXT"><em><phrase block_type="maker">e.</phrase> I don&#8217;t know.</em></p></li>
</list>
<p id="scc9e-ch04-p-265" block_type="CR-X-NL">What are the advantages and disadvantages of open and closed questions?</p>
</question>
<p id="scc9e_page_88" block_type="page_start" data-margin-content="left">88</p>
<question id="scc9e-ch04-ques-24" block_type="exercise_4_24.html">
<p id="scc9e-ch04-p-266" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.24 Telling the truth?</phrase> Many subjects don&#8217;t give honest answers to questions about activities that are illegal or sensitive in some other way. One study divided a large group of white adults into thirds at random. All were asked if they had ever used cocaine. The first group was interviewed by telephone: 21&#37; said Yes. In the group visited at home by an interviewer, 25&#37; said Yes. The final group was interviewed at home but answered the question on an anonymous form that they sealed in an envelope. Of this group, 28&#37; said they had used cocaine.</p>
<list id="scc9e-ch04-list-18" type="ordered" block_type="lower-alpha">
<li id="scc9e-ch04-li-66"><p id="scc9e-ch04-p-267" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(a)</phrase> Which result do you think is closest to the truth? Why?</p></li>
<li id="scc9e-ch04-li-67"><p id="scc9e-ch04-p-268" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(b)</phrase> Give two other examples of behavior you think would be underreported in a telephone survey.</p></li>
</list>
</question>
<question id="scc9e-ch04-ques-25" block_type="exercise_4_25.html">
<p id="scc9e-ch04-p-269" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.25 Did you vote?</phrase> When the Current Population Survey asked the adults in its sample of 56,000 households if they voted in the 2012 presidential election, 61.8&#37; said they had. The margin of error was less than 0.3&#37;. In fact, only 58.2&#37; of the adult population voted in that election. Why do you think the CPS result missed by 12 times the margin of error?</p>
</question>
<question id="scc9e-ch04-ques-26" block_type="exercise_4_26.html">
<p id="scc9e-ch04-p-270" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.26 A party poll.</phrase> At a party, there are 20 students over age 21 and 40 students under age 21. You choose, at random, two of those over 21 and separately choose at random four of those under 21 to interview about attitudes toward alcohol. You have given every student at the party the same chance to be interviewed: what is that chance? Why is your sample not an SRS?</p>
</question>
<question id="scc9e-ch04-ques-27" block_type="exercise_4_27.html">
<p id="scc9e-ch04-p-271" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.27 A stratified sample.</phrase> A club has 30 student members and 10 faculty members. The students are</p>
<list id="scc9e-ch04-list-19" type="unordered" block_type="none">
<li id="scc9e-ch04-li-68"><p id="scc9e-ch04-p-272" block_type="CR-X-NL">Aguirre</p></li>
<li id="scc9e-ch04-li-69"><p id="scc9e-ch04-p-273" block_type="CR-X-NL">Butterfield</p></li>
<li id="scc9e-ch04-li-70"><p id="scc9e-ch04-p-274" block_type="CR-X-NL">Caporuscio</p></li>
<li id="scc9e-ch04-li-71"><p id="scc9e-ch04-p-275" block_type="CR-X-NL">Carlson</p></li>
<li id="scc9e-ch04-li-72"><p id="scc9e-ch04-p-276" block_type="CR-X-NL">Chilson</p></li>
<li id="scc9e-ch04-li-73"><p id="scc9e-ch04-p-277" block_type="CR-X-NL">Clement</p></li>
<li id="scc9e-ch04-li-74"><p id="scc9e-ch04-p-278" block_type="CR-X-NL">Cooper</p></li>
<li id="scc9e-ch04-li-75"><p id="scc9e-ch04-p-279" block_type="CR-X-NL">Dobbs</p></li>
<li id="scc9e-ch04-li-76"><p id="scc9e-ch04-p-280" block_type="CR-X-NL">Freeman</p></li>
<li id="scc9e-ch04-li-77"><p id="scc9e-ch04-p-281" block_type="CR-X-NL">Girard</p></li>
<li id="scc9e-ch04-li-78"><p id="scc9e-ch04-p-282" block_type="CR-X-NL">Gonzales</p></li>
<li id="scc9e-ch04-li-79"><p id="scc9e-ch04-p-283" block_type="CR-X-NL">Grebe</p></li>
<li id="scc9e-ch04-li-80"><p id="scc9e-ch04-p-284" block_type="CR-X-NL">Kemp</p></li>
<li id="scc9e-ch04-li-81"><p id="scc9e-ch04-p-285" block_type="CR-X-NL">Kessler</p></li>
<li id="scc9e-ch04-li-82"><p id="scc9e-ch04-p-286" block_type="CR-X-NL">Koepnick</p></li>
<li id="scc9e-ch04-li-83"><p id="scc9e-ch04-p-287" block_type="CR-X-NL">Macha</p></li>
<li id="scc9e-ch04-li-84"><p id="scc9e-ch04-p-288" block_type="CR-X-NL">Makis</p></li>
<li id="scc9e-ch04-li-85"><p id="scc9e-ch04-p-289" block_type="CR-X-NL">Palacios</p></li>
<li id="scc9e-ch04-li-86"><p id="scc9e-ch04-p-290" block_type="CR-X-NL">Peralta</p></li>
<li id="scc9e-ch04-li-87"><p id="scc9e-ch04-p-291" block_type="CR-X-NL">Risser</p></li>
<li id="scc9e-ch04-li-88"><p id="scc9e-ch04-p-292" block_type="CR-X-NL">Rodriguez</p></li>
<li id="scc9e-ch04-li-89"><p id="scc9e-ch04-p-293" block_type="CR-X-NL">Ryndak</p></li>
<li id="scc9e-ch04-li-90"><p id="scc9e-ch04-p-294" block_type="CR-X-NL">Soria</p></li>
<li id="scc9e-ch04-li-91"><p id="scc9e-ch04-p-295" block_type="CR-X-NL">Spiel</p></li>
<li id="scc9e-ch04-li-92"><p id="scc9e-ch04-p-296" block_type="CR-X-NL">Stankiewicz</p></li>
<li id="scc9e-ch04-li-93"><p id="scc9e-ch04-p-297" block_type="CR-X-NL">Steele</p></li>
<li id="scc9e-ch04-li-94"><p id="scc9e-ch04-p-298" block_type="CR-X-NL">Tong</p></li>
<li id="scc9e-ch04-li-95"><p id="scc9e-ch04-p-299" block_type="CR-X-NL">White</p></li>
<li id="scc9e-ch04-li-96"><p id="scc9e-ch04-p-300" block_type="CR-X-NL">Williams</p></li>
<li id="scc9e-ch04-li-97"><p id="scc9e-ch04-p-301" block_type="CR-X-NL">Zhang</p></li>
</list>
<p id="scc9e-ch04-p-302" block_type="CR-X-NL">The faculty members are</p>
<list id="scc9e-ch04-list-20" type="unordered" block_type="none">
<li id="scc9e-ch04-li-98"><p id="scc9e-ch04-p-303" block_type="CR-X-NL">Atchade</p></li>
<li id="scc9e-ch04-li-99"><p id="scc9e-ch04-p-304" block_type="CR-X-NL">Craigmile</p></li>
<li id="scc9e-ch04-li-100"><p id="scc9e-ch04-p-305" block_type="CR-X-NL">Everson</p></li>
<li id="scc9e-ch04-li-101"><p id="scc9e-ch04-p-306" block_type="CR-X-NL">Fink</p></li>
<li id="scc9e-ch04-li-102"><p id="scc9e-ch04-p-307" block_type="CR-X-NL">Hansen</p></li>
<li id="scc9e-ch04-li-103"><p id="scc9e-ch04-p-308" block_type="CR-X-NL">Murphy</p></li>
<li id="scc9e-ch04-li-104"><p id="scc9e-ch04-p-309" block_type="CR-X-NL">Nair</p></li>
<li id="scc9e-ch04-li-105"><p id="scc9e-ch04-p-310" block_type="CR-X-NL">Nguyen</p></li>
<li id="scc9e-ch04-li-106"><p id="scc9e-ch04-p-311" block_type="CR-X-NL">Romero</p></li>
<li id="scc9e-ch04-li-107"><p id="scc9e-ch04-p-312" block_type="CR-X-NL">Turkmen</p></li>
</list>
<p id="scc9e-ch04-p-313" block_type="CR-X-NL">The club can send three students and two faculty members to a convention. It decides to choose those who will go by random selection.</p>
<list id="scc9e-ch04-list-21" type="ordered" block_type="lower-alpha">
<li id="scc9e-ch04-li-108"><p id="scc9e-ch04-p-314" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(a)</phrase> Use the <link href="http://digitalfirst.bfwpub.com/stats_applet/stats_applet_13_srs.html" target="_blank"><em>Simple Random Sample</em> applet</link>, other technology, or <link href="table_a.html">Table A</link> to choose a stratified random sample of three students and two faculty members.</p></li>
<li id="scc9e-ch04-li-109"><p id="scc9e-ch04-p-316" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(b)</phrase> What is the chance that the student named White is chosen? What is the chance that faculty member Romero is chosen?</p></li>
</list>
</question>
<p id="scc9e_page_89" block_type="page_start" data-margin-content="right">89</p>
<question id="scc9e-ch04-ques-28" block_type="exercise_4_28.html">
<p id="scc9e-ch04-p-317" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.28 A stratified sample.</phrase> A state university has 4900 in-state students and 2100 out-of-state students. A financial aid officer wants to poll the opinions of a random sample of students. In order to give adequate attention to the opinions of out-of-state students, the financial aid officer decides to choose a stratified random sample of 200 in-state students and 200 out-of-state students. The officer has alphabetized lists of in-state and out-of-state students.</p>
<list id="scc9e-ch04-list-22" type="ordered" block_type="lower-alpha">
<li id="scc9e-ch04-li-110"><p id="scc9e-ch04-p-318" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(a)</phrase> Explain how you would assign labels and use random digits to choose the desired sample. Use the <link href="http://digitalfirst.bfwpub.com/stats_applet/stats_applet_13_srs.html" target="_blank"><em>Simple Random Sample</em> applet</link>, other technology, or <link href="table_a.html">Table A</link> at line 122 and give the first five in-state students and the first five out-of-state students in your sample.</p></li>
<li id="scc9e-ch04-li-111"><p id="scc9e-ch04-p-319" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(b)</phrase> What is the chance that any one of the 4900 in-state students will be in your sample? What is the chance that any one of the 2100 out-of-state students will be in your sample?</p></li>
</list>
</question>
<question id="scc9e-ch04-ques-29" block_type="exercise_4_29.html">
<p id="scc9e-ch04-p-320" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.29 Sampling by accountants.</phrase> Accountants use stratified samples during audits to verify a company&#8217;s records of such things as accounts receivable. The stratification is based on the dollar amount of the item and often includes 100&#37; sampling of the largest items. One company reports 5000 accounts receivable. Of these, 100 are in amounts over &#36;50,000; 500 are in amounts between &#36;1000 and &#36;50,000; and the remaining 4400 are in amounts under &#36;1000. Using these groups as strata, you decide to verify all of the largest accounts and to sample 5&#37; of the midsize accounts and 1&#37; of the small accounts. How would you label the two strata from which you will sample? Use the <link href="http://digitalfirst.bfwpub.com/stats_applet/stats_applet_13_srs.html" target="_blank"><em>Simple Random Sample</em> applet</link>, other technology, or <link href="table_a.html">Table A</link>, starting at line 115, to select <em>only the first five</em> accounts from each of these strata.</p>
</question>
<question id="scc9e-ch04-ques-30" block_type="exercise_4_30.html">
<p id="scc9e-ch04-p-321" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.30 A sampling paradox?</phrase> <link href="example_4_8.html">Example 8</link> compares two SRSs of a university&#8217;s undergraduate and graduate students. The sample of undergraduates contains a smaller fraction of the population, 1 out of 90, versus 1 out of 15 for graduate students. Yet sampling 1 out of 90 undergraduates gives a smaller margin of error than sampling 1 out of 15 graduate students. Explain to someone who knows no statistics why this happens.</p>
</question>
<question id="scc9e-ch04-ques-31" block_type="exercise_4_31.html">
<p id="scc9e-ch04-p-323" block_type="CR-X-NL"><image asset-id="scc9e-ch04-img-news6" alt="image" src="asset/global_images/news.jpg"/>
<phrase block_type="CR-X-NL-N-ri">4.31 Appraising a poll.</phrase> <link href="exercise_4_22.html">Exercise 4.22</link> gives part of the description of a sample survey from <em>The New York Times</em>. It appears that the sample was taken in several stages. Why can we say this? The first stage no doubt used a stratified sample, though the <em>Times</em> does not say this. Explain why it would be bad practice to use an SRS from all possible telephone numbers rather than a stratified sample of landline-only, cell-phone-only, and dual-phone users.</p>
</question>
<question id="scc9e-ch04-ques-32" block_type="exercise_4_32.html">
<p id="scc9e-ch04-p-324" block_type="CR-X-NL"><image asset-id="scc9e-ch04-img-news7" alt="image" src="asset/global_images/news.jpg"/>
<phrase block_type="CR-X-NL-N-ri">4.32 Multistage sampling.</phrase> An article in the journal <em>Science</em> looks at differences in attitudes toward genetically modified foods between Europe and the United States. This calls for sample surveys. The European survey chose a sample of 1000 adults in each of 17 European countries. Here&#8217;s part of the description: &#8220;The Eurobarometer survey is a multistage, random-probability face-to-face sample survey.&#8221;</p>
<list id="scc9e-ch04-list-23" type="ordered" block_type="lower-alpha">
<li id="scc9e-ch04-li-112"><p id="scc9e-ch04-p-325" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(a)</phrase> What does &#8220;multistage&#8221; mean?</p></li>
<li id="scc9e-ch04-li-113"><p id="scc9e-ch04-p-326" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(b)</phrase> You can see that the first stage was stratified. What were the strata?</p></li>
<li id="scc9e-ch04-li-114"><p id="scc9e-ch04-p-327" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(c)</phrase> What does &#8220;random-probability sample&#8221; mean?</p></li>
</list>
</question>
<p id="scc9e_page_90" block_type="page_start" data-margin-content="left">90</p>
<question id="scc9e-ch04-ques-33" block_type="exercise_4_33.html">
<p id="scc9e-ch04-p-328" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.33 Online courses in high schools?</phrase> What do adults believe about requiring online courses in high schools? Are opinions different in urban, suburban, and rural areas? To find out, researchers wanted to ask adults this question:</p>
<p id="scc9e-ch04-p-329" block_type="CR-X-NL-EXT"><em>It has become common for education courses after high school to be taken online. In your opinion, should public high schools in your community require every student to take at least one course online while in high school?</em></p>
<p id="scc9e-ch04-p-330" block_type="CR-X-NL">Because most people live in heavily populated urban and suburban areas, an SRS might contain few rural adults. Moreover, it is too expensive to choose people at random from a large region. We should start by choosing school districts rather than people. Describe a suitable sample design for this study, and explain the reasoning behind your choice of design.</p>
</question>
<question id="scc9e-ch04-ques-34" block_type="exercise_4_34.html">
<p id="scc9e-ch04-p-331" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.34 Systematic random samples.</phrase> The last stage of the Current Population Survey (<link href="example_4_7.html">Example 7</link>) uses a <strong>systematic random sample</strong>. An example will illustrate the idea of a systematic sample. Suppose that we must choose four rooms out of the 100 rooms in a dormitory. Because 100<phrase data-math="math_6"></phrase>4 = 25, we can think of the list of 100 rooms as four lists of 25 rooms each. Choose one of the first 25 rooms at random, using <link href="table_a.html">Table A</link>. The sample will contain this room and the rooms 25, 50, and 75 places down the list from it. If 13 is chosen, for example, then the systematic random sample consists of the rooms numbered 13, 38, 63, and 88. Use <link href="table_a.html">Table A</link> to choose a systematic random sample of five rooms from a list of 200. Enter the table at line 120.</p>
</question>
<question id="scc9e-ch04-ques-35" block_type="exercise_4_35.html">
<p id="scc9e-ch04-p-332" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.35 Systematic isn&#8217;t simple.</phrase> <link href="exercise_4_34.html">Exercise 4.34</link> describes a systematic random sample. Like an SRS, a systematic sample gives all individuals the same chance to be chosen. Explain why this is true, then explain carefully why a systematic sample is nonetheless <em>not</em> an SRS.</p>
</question>
<question id="scc9e-ch04-ques-36" block_type="exercise_4_36.html">
<p id="scc9e-ch04-p-333" block_type="CR-X-NL">
<phrase block_type="CR-X-NL-N-ri">4.36 Planning a survey of students.</phrase> The student government plans to ask a random sample of students their opinions about on-campus parking. The university provides a list of the 20,000 enrolled students to serve as a sampling frame.</p>
<list id="scc9e-ch04-list-24" type="ordered" block_type="lower-alpha">
<li id="scc9e-ch04-li-115"><p id="scc9e-ch04-p-334" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(a)</phrase> How would you choose an SRS of 200 students?</p></li>
<li id="scc9e-ch04-li-116"><p id="scc9e-ch04-p-335" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(b)</phrase> How would you choose a systematic sample of 200 students? (See <link href="exercise_4_34.html">Exercise 4.34</link> to learn about systematic samples.)</p></li>
<li id="scc9e-ch04-li-117"><p id="scc9e-ch04-p-336" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(c)</phrase> The list shows whether students live on campus (8000 students) or off campus (12,000 students). How would you choose a stratified sample of 50 on-campus students and 150 off-campus students?</p></li>
</list>
</question>
<p id="scc9e_page_91" block_type="page_start" data-margin-content="right">91</p>
<question id="scc9e-ch04-ques-37" block_type="exercise_4_37.html">
<p id="scc9e-ch04-p-338" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.37 Sampling students.</phrase> You want to investigate the attitudes of students at your school toward the school&#8217;s policy on extra fees for lab courses. You have a grant that will pay the costs of contacting about 500 students.</p>
<list id="scc9e-ch04-list-25" type="ordered" block_type="lower-alpha">
<li id="scc9e-ch04-li-118"><p id="scc9e-ch04-p-339" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(a)</phrase> Specify the exact population for your study. For example, will you include part-time students?</p></li>
<li id="scc9e-ch04-li-119"><p id="scc9e-ch04-p-340" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(b)</phrase> Describe your sample design. For example, will you use a stratified sample with student majors as strata?</p></li>
<li id="scc9e-ch04-li-120"><p id="scc9e-ch04-p-341" block_type="CR-X-NL-lvl2"><phrase block_type="maker">(c)</phrase> Briefly discuss the practical difficulties that you anticipate. For example, how will you contact the students in your sample?</p></li>
</list>
</question>
<question id="scc9e-ch04-ques-38" block_type="exercise_4_38.html">
<p id="scc9e-ch04-p-342" block_type="CR-X-NL"><phrase block_type="CR-X-NL-N-ri">4.38 Mall interviews.</phrase> <link href="example_2_1.html">Example 1</link> in <link href="scc9e-ch02.xml">Chapter 2</link> (page 23) describes mall interviewing. This is an example of a convenience sample. Why do mall interviews not produce probability samples?</p>
</question>
<question id="scc9e-ch04-ques-39" block_type="exercise_4_39.html">
<p id="scc9e-ch04-p-343" block_type="CR-X-NL"><image asset-id="scc9e-ch04-img-news8" alt="image" src="asset/global_images/news.jpg"/><phrase block_type="CR-X-NL-N-ri">4.39 Partial-birth abortion?</phrase> Here are three opinion poll questions on the same issue, with the poll results:</p>
<p id="scc9e-ch04-p-344" block_type="CR-X-NL-EXT"><em>As you may know, the Supreme Court recently upheld a law that makes the procedure commonly known as a partial birth abortion illegal. Do you favor or oppose this ruling by the Supreme Court?</em> Result: 53&#37; favor; 34&#37; oppose.</p>
<p id="scc9e-ch04-p-345" block_type="CR-X-NL-EXT"><em>[T]he Supreme Court . . . upheld a law that makes . . . partial birth abortion illegal. [This] procedure [is] performed in the late-term of pregnancy, when in some cases the baby is old enough to survive. . . . The court&#8217;s ruling . . . [doesn&#8217;t] make an exception for the [mother&#8217;s] health. . . . Do you favor or oppose this ruling . . . ?</em> Result: 47&#37; favor; 43&#37; oppose.</p>
<p id="scc9e-ch04-p-346" block_type="CR-X-NL-EXT"><em>. . . I would like to ask your opinion about a specific abortion procedure known as a &#8220;late-term&#8221; . . . or &#8220;partial-birth&#8221; abortion, which is sometimes performed . . . during the last few months of pregnancy. Do you think . . . the government should make this procedure illegal, or do you think . . . the procedure should be legal?</em> Result: 66&#37; illegal; 28&#37; legal.</p>
<p id="scc9e-ch04-p-347" block_type="CR-X-NL">Using this example, discuss the difficulty of using responses to opinion polls to understand public opinion.</p>
</question>
<box id="scc9e-ch04-box-25" numbered="false" block_type="exploring-web">
<p id="scc9e-ch04-p-348" block_type="QRL icon"><image asset-id="scc9e-ch04-img-18" alt="image" src="asset/global_images/bar_code.jpg"/></p>
<p id="scc9e-ch04-p-349" block_type="WEB"><strong>EXPLORING</strong> THE WEB</p>
<p id="scc9e-ch04-p-350" block_type="WEBTX"><em>Follow the QR code to access exercises.</em></p>
</box>
</section>
</chapter>